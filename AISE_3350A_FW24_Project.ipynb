{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <center><b>AISE 3350A TEAM 12: Group Project</b></center>\n",
    "\n",
    "<center>December 3rd, 2024</center>\n",
    "\n",
    "- Rayyan Syed Nezami\n",
    "- Kayla-Jane Kanga\n",
    "- Yeni Shekan-Olaosegba\n",
    "- Rafi Mettaias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-Enhanced Candy Inventory System Group Project\n",
    "\n",
    "***\n",
    "\n",
    "## Table of Contents\n",
    "- [Code](##Code)\n",
    "- [Introduction](##Introduction)\n",
    "- [Methods](##Method)\n",
    "- [Results](##Results)\n",
    "- [Discussion](##Discussion)\n",
    "- [Conclusion](##Conclusion)\n",
    "- [Bibliograpghy](##Bibliography)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for the M&M Counter System\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebcamCapture:\n",
    "    \"\"\"\n",
    "    Handles webcam operations including initialization, capture, and resource management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, camera_id: int = 0):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self.camera = None\n",
    "        self.is_capturing = False\n",
    "        self.camera_id = camera_id\n",
    "        \n",
    "        # Default camera settings\n",
    "        self.frame_width = 1280\n",
    "        self.frame_height = 720\n",
    "        self.fps = 30\n",
    "        \n",
    "        # Camera parameters\n",
    "        self.camera_settings = {\n",
    "            cv2.CAP_PROP_FRAME_WIDTH: self.frame_width,\n",
    "            cv2.CAP_PROP_FRAME_HEIGHT: self.frame_height,\n",
    "            cv2.CAP_PROP_FPS: self.fps,\n",
    "            cv2.CAP_PROP_AUTOFOCUS: 1,\n",
    "            cv2.CAP_PROP_BRIGHTNESS: 128,\n",
    "            cv2.CAP_PROP_CONTRAST: 128,\n",
    "            cv2.CAP_PROP_SATURATION: 128\n",
    "        }\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.frame_count = 0\n",
    "        self.start_time = None\n",
    "        \n",
    "    def initialize_camera(self, camera_id: Optional[int] = None) -> bool:\n",
    "        try:\n",
    "            if camera_id is not None:\n",
    "                self.camera_id = camera_id\n",
    "                \n",
    "            self.camera = cv2.VideoCapture(self.camera_id)\n",
    "            \n",
    "            if not self.camera.isOpened():\n",
    "                self.logger.error(f\"Failed to open camera {self.camera_id}\")\n",
    "                return False\n",
    "                \n",
    "            for prop, value in self.camera_settings.items():\n",
    "                self.camera.set(prop, value)\n",
    "                \n",
    "            actual_width = self.camera.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            actual_height = self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "            \n",
    "            self.logger.info(f\"Camera initialized: {actual_width}x{actual_height}\")\n",
    "            \n",
    "            self.frame_count = 0\n",
    "            self.start_time = time.time()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing camera: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def capture_frame(self) -> Optional[np.ndarray]:\n",
    "        if self.camera is None:\n",
    "            self.logger.error(\"Camera not initialized\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            ret, frame = self.camera.read()\n",
    "            \n",
    "            if ret:\n",
    "                self.frame_count += 1\n",
    "                return frame\n",
    "            else:\n",
    "                self.logger.error(\"Failed to capture frame\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error capturing frame: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def get_fps(self) -> float:\n",
    "        if self.start_time is None or self.frame_count == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return self.frame_count / elapsed_time if elapsed_time > 0 else 0.0\n",
    "        \n",
    "    def get_camera_properties(self) -> Dict:\n",
    "        if self.camera is None:\n",
    "            return {}\n",
    "            \n",
    "        properties = {\n",
    "            'width': self.camera.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "            'height': self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT),\n",
    "            'fps': self.camera.get(cv2.CAP_PROP_FPS),\n",
    "            'brightness': self.camera.get(cv2.CAP_PROP_BRIGHTNESS),\n",
    "            'contrast': self.camera.get(cv2.CAP_PROP_CONTRAST),\n",
    "            'saturation': self.camera.get(cv2.CAP_PROP_SATURATION),\n",
    "            'auto_focus': self.camera.get(cv2.CAP_PROP_AUTOFOCUS),\n",
    "            'actual_fps': self.get_fps()\n",
    "        }\n",
    "        return properties\n",
    "        \n",
    "    def set_camera_property(self, property_id: int, value: float) -> bool:\n",
    "        if self.camera is None:\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            return self.camera.set(property_id, value)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting camera property: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def set_resolution(self, width: int, height: int) -> bool:\n",
    "        try:\n",
    "            success = True\n",
    "            success &= self.set_camera_property(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "            success &= self.set_camera_property(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "            \n",
    "            if success:\n",
    "                self.frame_width = width\n",
    "                self.frame_height = height\n",
    "                self.logger.info(f\"Resolution set to {width}x{height}\")\n",
    "            \n",
    "            return success\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting resolution: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def start_preview(self, window_name: str = \"Camera Preview\") -> None:\n",
    "        if self.camera is None:\n",
    "            self.logger.error(\"Camera not initialized\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            self.is_capturing = True\n",
    "            \n",
    "            while self.is_capturing:\n",
    "                frame = self.capture_frame()\n",
    "                \n",
    "                if frame is not None:\n",
    "                    cv2.imshow(window_name, frame)\n",
    "                    \n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                        \n",
    "            cv2.destroyWindow(window_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in preview: {str(e)}\")\n",
    "            self.is_capturing = False\n",
    "            \n",
    "    def stop_preview(self) -> None:\n",
    "        self.is_capturing = False\n",
    "        \n",
    "    def release(self) -> None:\n",
    "        try:\n",
    "            if self.camera is not None:\n",
    "                self.camera.release()\n",
    "                self.camera = None\n",
    "                self.is_capturing = False\n",
    "                self.logger.info(\"Camera resources released\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error releasing camera: {str(e)}\")\n",
    "            \n",
    "    def __del__(self):\n",
    "        self.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Handles image processing operations for M&M detection.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        blur_kernel_size: Size of Gaussian blur kernel\n",
    "        adaptive_block_size: Block size for adaptive thresholding\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Processing parameters\n",
    "        self.blur_kernel_size = (5, 5)\n",
    "        self.adaptive_block_size = 11\n",
    "        self.clahe_parameters = {\n",
    "            'clip_limit': 2.0,\n",
    "            'tile_grid_size': (8, 8)\n",
    "        }\n",
    "        #sharpens the image\n",
    "        self.sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "        \n",
    "        \n",
    "    def preprocess_image(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocess image for M&M detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image in BGR format\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - Grayscale processed image\n",
    "                - HSV image\n",
    "                - Blurred image\n",
    "                \n",
    "        Raises:\n",
    "            ValueError: If input image is None or empty\n",
    "            Exception: For other processing errors\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if image is None or image.size == 0:\n",
    "                raise ValueError(\"Invalid input image\")\n",
    "                \n",
    "            # Convert to HSV for better color detection\n",
    "            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "                     # Apply CLAHE to normalize lighting\n",
    "            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clahe_parameters['clip_limit'],\n",
    "                                    tileGridSize=self.clahe_parameters['tile_grid_size'])\n",
    "            l = clahe.apply(l)\n",
    "            lab = cv2.merge((l, a, b))\n",
    "            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "            # Apply Gaussian blur to reduce noise\n",
    "            blurred = cv2.GaussianBlur(image, self.blur_kernel_size, 0)\n",
    "            \n",
    "            # Convert blurred image to grayscale\n",
    "            gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            return gray, hsv, blurred\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in preprocessing: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def enhance_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Enhance image quality for better detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create a copy of the input image\n",
    "            enhanced = image.copy()\n",
    "            \n",
    "            # Convert to LAB color space\n",
    "            lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)\n",
    "            \n",
    "            # Split the LAB image into L, A, and B channels\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE to L channel\n",
    "            clahe = cv2.createCLAHE(\n",
    "                clipLimit=self.clahe_parameters['clip_limit'],\n",
    "                tileGridSize=self.clahe_parameters['tile_grid_size']\n",
    "            )\n",
    "            cl = clahe.apply(l)\n",
    "            \n",
    "            # Merge the CLAHE enhanced L-channel back with A and B channels\n",
    "            limg = cv2.merge((cl, a, b))\n",
    "            \n",
    "            # Convert back to BGR color space\n",
    "            enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "            \n",
    "            return enhanced\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in image enhancement: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def adjust_brightness_contrast(self, image: np.ndarray, \n",
    "                                 alpha: float = 1.0, \n",
    "                                 beta: int = 0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Adjust image brightness and contrast.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            alpha: Contrast control (1.0-3.0)\n",
    "            beta: Brightness control (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            Adjusted image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate parameters\n",
    "            alpha = max(0.0, min(3.0, alpha))\n",
    "            beta = max(0, min(100, beta))\n",
    "            \n",
    "            # Apply brightness and contrast adjustment\n",
    "            adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "            \n",
    "            return adjusted\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in brightness/contrast adjustment: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def denoise_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply denoising to the image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Denoised image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Apply non-local means denoising\n",
    "            denoised = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "            return denoised\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in denoising: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def sharpen_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply sharpening to the image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Sharpened image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create sharpening kernel\n",
    "            kernel = np.array([[-1,-1,-1],\n",
    "                             [-1, 9,-1],\n",
    "                             [-1,-1,-1]])\n",
    "            \n",
    "            # Apply sharpening\n",
    "            sharpened = cv2.filter2D(image, -1, kernel)\n",
    "            \n",
    "            return sharpened\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in sharpening: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def process_for_detection(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Complete processing pipeline for M&M detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing processed images for detection:\n",
    "                - Grayscale image\n",
    "                - HSV image\n",
    "                - Blurred image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Enhance image\n",
    "            enhanced = self.enhance_image(image)\n",
    "            \n",
    "            # Denoise\n",
    "            denoised = self.denoise_image(enhanced)\n",
    "            \n",
    "            # Adjust brightness and contrast\n",
    "            adjusted = self.adjust_brightness_contrast(denoised, 1.2, 10)\n",
    "            \n",
    "            # Get processed images\n",
    "            gray, hsv, blurred = self.preprocess_image(adjusted)\n",
    "            \n",
    "            return gray, hsv, blurred\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in detection processing: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def get_processing_parameters(self) -> dict:\n",
    "        \"\"\"\n",
    "        Get current processing parameters.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of current processing parameters\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'blur_kernel_size': self.blur_kernel_size,\n",
    "            'adaptive_block_size': self.adaptive_block_size,\n",
    "            'clahe_parameters': self.clahe_parameters\n",
    "        }\n",
    "        \n",
    "    def set_processing_parameters(self, \n",
    "                                blur_kernel_size: Optional[Tuple[int, int]] = None,\n",
    "                                adaptive_block_size: Optional[int] = None,\n",
    "                                clahe_clip_limit: Optional[float] = None,\n",
    "                                clahe_grid_size: Optional[Tuple[int, int]] = None) -> None:\n",
    "        \"\"\"\n",
    "        Set processing parameters.\n",
    "        \n",
    "        Args:\n",
    "            blur_kernel_size: Size of Gaussian blur kernel\n",
    "            adaptive_block_size: Block size for adaptive thresholding\n",
    "            clahe_clip_limit: Clip limit for CLAHE\n",
    "            clahe_grid_size: Grid size for CLAHE\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if blur_kernel_size is not None:\n",
    "                self.blur_kernel_size = blur_kernel_size\n",
    "            if adaptive_block_size is not None:\n",
    "                self.adaptive_block_size = adaptive_block_size\n",
    "            if clahe_clip_limit is not None:\n",
    "                self.clahe_parameters['clip_limit'] = clahe_clip_limit\n",
    "            if clahe_grid_size is not None:\n",
    "                self.clahe_parameters['tile_grid_size'] = clahe_grid_size\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting processing parameters: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMDetector:\n",
    "    \"\"\"\n",
    "    Handles M&M detection and color classification.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        min_radius: Minimum radius for M&M detection\n",
    "        max_radius: Maximum radius for M&M detection\n",
    "        min_dist: Minimum distance between detected circles\n",
    "        param1: First parameter for Hough Circle detection\n",
    "        param2: Second parameter for Hough Circle detection\n",
    "        color_ranges: HSV color ranges for M&M classification\n",
    "    \"\"\"\n",
    "    def process_image(self, gray: np.ndarray, hsv: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Process the image to detect M&Ms and identify their colors.\n",
    "\n",
    "        Args:\n",
    "            gray: Grayscale image for circle detection.\n",
    "            hsv: HSV image for color identification.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "                - circles: Detected circles (x, y, radius) as a NumPy array.\n",
    "                - colors: List of identified colors for each circle.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Detect circles using Hough Transform\n",
    "            circles = self.detect_circles(gray)\n",
    "\n",
    "            # If no circles detected, return empty results\n",
    "            if circles is None or len(circles) == 0:\n",
    "                return np.array([]), []\n",
    "\n",
    "            # Identify colors of the detected circles\n",
    "            colors = self.identify_colors(hsv, circles)\n",
    "\n",
    "            return circles, colors\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.getLogger(__name__).error(f\"Error in process_image: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Circle detection parameters\n",
    "        self.min_radius = 5\n",
    "        self.max_radius = 40\n",
    "        self.min_dist = 15\n",
    "        self.param1 = 50  # Edge detection parameter\n",
    "        self.param2 = 30  # Circle detection parameter\n",
    "        \n",
    "        # Define color ranges in HSV format\n",
    "        \n",
    "        self.color_ranges = {\n",
    "    'red': [\n",
    "        {'lower': np.array([0, 30, 30]), 'upper': np.array([10, 255, 255])},\n",
    "        {'lower': np.array([170, 30, 30]), 'upper': np.array([180, 255, 255])}\n",
    "    ],\n",
    "    'blue': {\n",
    "        'lower': np.array([90, 50, 50]),\n",
    "        'upper': np.array([130, 255, 255])\n",
    "    },\n",
    "    'green': {\n",
    "        'lower': np.array([35, 50, 50]),\n",
    "        'upper': np.array([85, 255, 255])\n",
    "    },\n",
    "    'yellow': {\n",
    "        'lower': np.array([20, 50, 50]),\n",
    "        'upper': np.array([40, 255, 255])\n",
    "    },\n",
    "    'orange': {\n",
    "        'lower': np.array([10, 100, 50]),  # Adjusted for brighter orange\n",
    "        'upper': np.array([25, 255, 255])\n",
    "    },\n",
    "    'purple': {  # New color range for purple\n",
    "        'lower': np.array([130, 50, 50]),\n",
    "        'upper': np.array([160, 255, 255])\n",
    "    },\n",
    "    'brown': {\n",
    "        'lower': np.array([0, 50, 20]),\n",
    "        'upper': np.array([20, 200, 100])\n",
    "    }\n",
    "}\n",
    "\n",
    "    def visualize_hsv_ranges(self, image_path: str):\n",
    "        \"\"\"\n",
    "        Visualize the HSV masks for each color range.\n",
    "\n",
    "        Args:\n",
    "            image_path: Path to the image file.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        for color, ranges in self.color_ranges.items():\n",
    "            if isinstance(ranges, list):  # Handle multi-range colors like red\n",
    "                mask = cv2.inRange(hsv_image, ranges[0]['lower'], ranges[0]['upper'])\n",
    "                mask += cv2.inRange(hsv_image, ranges[1]['lower'], ranges[1]['upper'])\n",
    "            else:\n",
    "                mask = cv2.inRange(hsv_image, ranges['lower'], ranges['upper'])\n",
    "            \n",
    "            cv2.imshow(f\"{color} Mask\", mask)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def adjust_detection_params(self, min_radius: int = None, max_radius: int = None, min_dist: int = None,\n",
    "                                param1: int = None, param2: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Adjusts the detection parameters dynamically.\n",
    "\n",
    "        Args:\n",
    "            min_radius: Minimum circle radius for detection.\n",
    "            max_radius: Maximum circle radius for detection.\n",
    "            min_dist: Minimum distance between detected circles.\n",
    "            param1: First parameter for Hough Circle detection (e.g., for edge detection).\n",
    "            param2: Second parameter for Hough Circle detection (e.g., for circle detection).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if min_radius is not None:\n",
    "                self.min_radius = min_radius\n",
    "            if max_radius is not None:\n",
    "                self.max_radius = max_radius\n",
    "            if min_dist is not None:\n",
    "                self.min_dist = min_dist\n",
    "            if param1 is not None:\n",
    "                self.param1 = param1\n",
    "            if param2 is not None:\n",
    "                self.param2 = param2\n",
    "\n",
    "            self.logger.info(\"Detection parameters updated successfully.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error adjusting detection parameters: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    # Other methods like _is_in_range, _classify_color, draw_results...\n",
    "        # Detection parameters history for analysis\n",
    "        self.detection_history = []\n",
    "        \n",
    "    def detect_circles(self, gray: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Detect circles in the grayscale image using Hough Circle Transform.\n",
    "        \n",
    "        Args:\n",
    "            gray: Grayscale input image\n",
    "            \n",
    "        Returns:\n",
    "            Array of detected circles (x, y, radius)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            circles = cv2.HoughCircles(\n",
    "                gray, cv2.HOUGH_GRADIENT, dp=1, minDist=self.min_dist,\n",
    "                param1=self.param1, param2=self.param2,\n",
    "                minRadius=self.min_radius, maxRadius=self.max_radius\n",
    "            )\n",
    "            if circles is not None:\n",
    "                circles = np.uint16(np.around(circles))\n",
    "                return circles[0]\n",
    "            return np.array([])\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in circle detection: {str(e)}\")\n",
    "            raise\n",
    "    def _is_in_range(self, hsv_color: np.ndarray, lower: np.ndarray, upper: np.ndarray) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the HSV color falls within the given range.\n",
    "\n",
    "        Args:\n",
    "            hsv_color: HSV color values as a NumPy array (e.g., [H, S, V]).\n",
    "            lower: Lower bound of the HSV range as a NumPy array.\n",
    "            upper: Upper bound of the HSV range as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            True if the color is within range, otherwise False.\n",
    "        \"\"\"\n",
    "        return np.all(lower <= hsv_color) and np.all(hsv_color <= upper)\n",
    "    def identify_colors(self, hsv: np.ndarray, circles: np.ndarray) -> List[str]:\n",
    "        \"\"\"\n",
    "        Identify colors of detected M&Ms.\n",
    "        \n",
    "        Args:\n",
    "            hsv: HSV format image\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            List of color names for each detected M&M\n",
    "        \"\"\"\n",
    "        try:\n",
    "            colors = []\n",
    "            for (x, y, r) in circles:\n",
    "                mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "                cv2.circle(mask, (x, y), r - 2, 255, -1)\n",
    "\n",
    "                mean_hsv = cv2.mean(hsv, mask=mask)[:3]\n",
    "                detected_color = self._classify_color(mean_hsv)\n",
    "                colors.append(detected_color)\n",
    "            return colors\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in color identification: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _classify_color(self, hsv_color: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Classify color based on HSV values.\n",
    "\n",
    "        Args:\n",
    "         hsv_color: HSV color values.\n",
    "\n",
    "        Returns:\n",
    "            Identified color name.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for color, ranges in self.color_ranges.items():\n",
    "                if isinstance(ranges, list):  # Handle multiple ranges (e.g., 'red')\n",
    "                    for range_set in ranges:\n",
    "                        if self._is_in_range(hsv_color, range_set['lower'], range_set['upper']):\n",
    "                            return color\n",
    "                else:  # Handle single range\n",
    "                    if self._is_in_range(hsv_color, ranges['lower'], ranges['upper']):\n",
    "                        return color\n",
    "            return 'unknown'  # Default return if no match found\n",
    "        except Exception as e:\n",
    "            logging.getLogger(__name__).error(f\"Error in color classification: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def draw_results(self, image: np.ndarray, circles: np.ndarray, colors: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draws detected circles and their associated colors on the image.\n",
    "\n",
    "        Args:\n",
    "            image: Original input image.\n",
    "            circles: Detected circles as an array of (x, y, radius).\n",
    "            colors: List of color names corresponding to the detected circles.\n",
    "\n",
    "        Returns:\n",
    "            Annotated image with drawn circles and color labels.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Make a copy of the image to draw on\n",
    "            result_image = image.copy()\n",
    "\n",
    "            # Loop through each detected circle\n",
    "            for (x, y, r), color in zip(circles, colors):\n",
    "                # Draw the circle\n",
    "                cv2.circle(result_image, (x, y), r, (0, 255, 0), 2)  # Green circle outline\n",
    "\n",
    "                # Add color label text\n",
    "                cv2.putText(result_image, color, (x - r, y - r - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.5, (255, 255, 255), 2)  # White text\n",
    "\n",
    "            return result_image\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error drawing results: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes and validates M&M detection results, generating statistics and reports.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        history: List of previous results for trend analysis\n",
    "        validation_thresholds: Dictionary of validation thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize result history\n",
    "        self.history: List[Dict] = []\n",
    "        \n",
    "        # Define validation thresholds\n",
    "        self.validation_thresholds = {\n",
    "            'min_count': 1,\n",
    "            'max_count': 50,\n",
    "            'min_radius': 8,\n",
    "            'max_radius': 35,\n",
    "            'min_distance': 15,\n",
    "            'max_overlap': 0.3\n",
    "        }\n",
    "        \n",
    "    def analyze_results(self, circles: np.ndarray, \n",
    "                       colors: List[str],\n",
    "                       timestamp: Optional[datetime.datetime] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze detection results and generate statistics.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            timestamp: Time of detection\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate inputs\n",
    "            if len(circles) != len(colors):\n",
    "                raise ValueError(\"Mismatch between circles and colors count\")\n",
    "                \n",
    "            # Create result dictionary\n",
    "            results = {\n",
    "                'timestamp': timestamp or datetime.datetime.now().isoformat(),\n",
    "                'total_count': len(circles),\n",
    "                'color_distribution': dict(Counter(colors)),\n",
    "                'spatial_statistics': self._calculate_spatial_statistics(circles),\n",
    "                'radius_statistics': self._calculate_radius_statistics(circles),\n",
    "                'validation_results': self._validate_results(circles, colors),\n",
    "                'confidence_metrics': self._calculate_confidence_metrics(circles, colors)\n",
    "            }\n",
    "            \n",
    "            # Add to history\n",
    "            self.history.append(results)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in result analysis: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_spatial_statistics(self, circles: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate spatial statistics for detected M&Ms.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing spatial statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(circles) == 0:\n",
    "                return {'density': 0, 'average_spacing': 0}\n",
    "                \n",
    "            # Extract center points\n",
    "            centers = circles[:, :2]\n",
    "            \n",
    "            # Calculate pairwise distances\n",
    "            distances = []\n",
    "            for i in range(len(centers)):\n",
    "                for j in range(i + 1, len(centers)):\n",
    "                    dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                    distances.append(dist)\n",
    "                    \n",
    "            # Calculate area\n",
    "            area = (np.max(centers[:, 0]) - np.min(centers[:, 0])) * \\\n",
    "                   (np.max(centers[:, 1]) - np.min(centers[:, 1]))\n",
    "                   \n",
    "            stats = {\n",
    "                'density': len(circles) / area if area > 0 else 0,\n",
    "                'average_spacing': np.mean(distances) if distances else 0,\n",
    "                'min_spacing': np.min(distances) if distances else 0,\n",
    "                'max_spacing': np.max(distances) if distances else 0,\n",
    "                'spacing_std': np.std(distances) if distances else 0\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating spatial statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_radius_statistics(self, circles: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate statistics for M&M radii.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing radius statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(circles) == 0:\n",
    "                return {\n",
    "                    'average_radius': 0,\n",
    "                    'radius_std': 0,\n",
    "                    'min_radius': 0,\n",
    "                    'max_radius': 0\n",
    "                }\n",
    "                \n",
    "            radii = circles[:, 2]\n",
    "            \n",
    "            stats = {\n",
    "                'average_radius': float(np.mean(radii)),\n",
    "                'radius_std': float(np.std(radii)),\n",
    "                'min_radius': float(np.min(radii)),\n",
    "                'max_radius': float(np.max(radii)),\n",
    "                'radius_variation': float(np.std(radii) / np.mean(radii))\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating radius statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_confidence_metrics(self, circles: np.ndarray, \n",
    "                                   colors: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate confidence metrics for detection results.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing confidence metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            metrics = {\n",
    "                'detection_confidence': 0.0,\n",
    "                'color_confidence': 0.0,\n",
    "                'overall_confidence': 0.0\n",
    "            }\n",
    "            \n",
    "            if len(circles) == 0:\n",
    "                return metrics\n",
    "                \n",
    "            # Detection confidence based on radius consistency\n",
    "            radii = circles[:, 2]\n",
    "            radius_variation = np.std(radii) / np.mean(radii)\n",
    "            detection_confidence = max(0, 1 - radius_variation)\n",
    "            \n",
    "            # Color confidence based on known colors\n",
    "            known_colors = len([c for c in colors if c != 'unknown'])\n",
    "            color_confidence = known_colors / len(colors) if colors else 0\n",
    "            \n",
    "            # Overall confidence\n",
    "            metrics.update({\n",
    "                'detection_confidence': float(detection_confidence),\n",
    "                'color_confidence': float(color_confidence),\n",
    "                'overall_confidence': float((detection_confidence + color_confidence) / 2)\n",
    "            })\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating confidence metrics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _validate_results(self, circles: np.ndarray, colors: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Validate detection results against thresholds.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing validation results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            validation = {\n",
    "                'count_valid': True,\n",
    "                'radius_valid': True,\n",
    "                'spacing_valid': True,\n",
    "                'overlap_valid': True,\n",
    "                'warnings': []\n",
    "            }\n",
    "            \n",
    "            # Validate count\n",
    "            if len(circles) < self.validation_thresholds['min_count']:\n",
    "                validation['count_valid'] = False\n",
    "                validation['warnings'].append(\"Too few M&Ms detected\")\n",
    "            elif len(circles) > self.validation_thresholds['max_count']:\n",
    "                validation['count_valid'] = False\n",
    "                validation['warnings'].append(\"Too many M&Ms detected\")\n",
    "                \n",
    "            # Validate radii\n",
    "            radii = circles[:, 2]\n",
    "            if np.any(radii < self.validation_thresholds['min_radius']) or \\\n",
    "               np.any(radii > self.validation_thresholds['max_radius']):\n",
    "                validation['radius_valid'] = False\n",
    "                validation['warnings'].append(\"Invalid M&M sizes detected\")\n",
    "                \n",
    "            # Validate spacing\n",
    "            centers = circles[:, :2]\n",
    "            for i in range(len(centers)):\n",
    "                for j in range(i + 1, len(centers)):\n",
    "                    dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                    if dist < self.validation_thresholds['min_distance']:\n",
    "                        validation['spacing_valid'] = False\n",
    "                        validation['warnings'].append(\"M&Ms too close together\")\n",
    "                        break\n",
    "                        \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in result validation: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def generate_report(self, results: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Generate a formatted report of analysis results.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            report = [\n",
    "                \"M&M Detection Analysis Report\",\n",
    "                f\"Timestamp: {results['timestamp']}\",\n",
    "                f\"\\nTotal M&Ms detected: {results['total_count']}\",\n",
    "                \"\\nColor Distribution:\"\n",
    "            ]\n",
    "            \n",
    "            for color, count in results['color_distribution'].items():\n",
    "                report.append(f\"  {color}: {count}\")\n",
    "                \n",
    "            report.extend([\n",
    "                \"\\nSpatial Statistics:\",\n",
    "                f\"  Average spacing: {results['spatial_statistics']['average_spacing']:.2f} pixels\",\n",
    "                f\"  Density: {results['spatial_statistics']['density']:.4f} M&Ms/pixelÂ²\",\n",
    "                \"\\nSize Statistics:\",\n",
    "                f\"  Average radius: {results['radius_statistics']['average_radius']:.2f} pixels\",\n",
    "                f\"  Radius std dev: {results['radius_statistics']['radius_std']:.2f} pixels\",\n",
    "                \"\\nConfidence Metrics:\",\n",
    "                f\"  Detection confidence: {results['confidence_metrics']['detection_confidence']:.2%}\",\n",
    "                f\"  Color confidence: {results['confidence_metrics']['color_confidence']:.2%}\",\n",
    "                f\"  Overall confidence: {results['confidence_metrics']['overall_confidence']:.2%}\"\n",
    "            ])\n",
    "            \n",
    "            if results['validation_results']['warnings']:\n",
    "                report.extend([\n",
    "                    \"\\nWarnings:\",\n",
    "                    *[f\"  - {warning}\" for warning in results['validation_results']['warnings']]\n",
    "                ])\n",
    "                \n",
    "            return \"\\n\".join(report)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating report: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def plot_results(self, results: Dict, save_path: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Generate visualization plots for results.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            save_path: Optional path to save plots\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.style.use('seaborn')\n",
    "            \n",
    "            # Create figure with subplots\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Color distribution\n",
    "            ax1 = plt.subplot(2, 2, 1)\n",
    "            colors = list(results['color_distribution'].keys())\n",
    "            counts = list(results['color_distribution'].values())\n",
    "            ax1.bar(colors, counts)\n",
    "            ax1.set_title('Color Distribution')\n",
    "            ax1.set_xlabel('Color')\n",
    "            ax1.set_ylabel('Count')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Radius distribution\n",
    "            ax2 = plt.subplot(2, 2, 2)\n",
    "            ax2.hist(results['radius_statistics']['average_radius'], bins=10)\n",
    "            ax2.set_title('Radius Distribution')\n",
    "            ax2.set_xlabel('Radius (pixels)')\n",
    "            ax2.set_ylabel('Frequency')\n",
    "            \n",
    "            # Confidence metrics\n",
    "            ax3 = plt.subplot(2, 2, 3)\n",
    "            confidence_metrics = results['confidence_metrics']\n",
    "            ax3.bar(['Detection', 'Color', 'Overall'], \n",
    "                   [confidence_metrics['detection_confidence'],\n",
    "                    confidence_metrics['color_confidence'],\n",
    "                    confidence_metrics['overall_confidence']])\n",
    "            ax3.set_title('Confidence Metrics')\n",
    "            ax3.set_ylim(0, 1)\n",
    "            \n",
    "            # Spatial distribution\n",
    "            ax4 = plt.subplot(2, 2, 4)\n",
    "            spatial_stats = results['spatial_statistics']\n",
    "            ax4.bar(['Min', 'Avg', 'Max'],\n",
    "                   [spatial_stats['min_spacing'],\n",
    "                    spatial_stats['average_spacing'],\n",
    "                    spatial_stats['max_spacing']])\n",
    "            ax4.set_title('Spacing Distribution')\n",
    "            ax4.set_ylabel('Pixels')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error plotting results: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def save_results(self, results: Dict, filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save results to JSON file.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            filepath: Path to save file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "                \n",
    "            self.logger.info(f\"Results saved to {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving results: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def get_history_statistics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate statistics across historical results.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing historical statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.history:\n",
    "                return {}\n",
    "                \n",
    "            total_counts = [result['total_count'] for result in self.history]\n",
    "            \n",
    "            stats = {\n",
    "                'average_count': np.mean(total_counts),\n",
    "                'count_std': np.std(total_counts),\n",
    "                'min_count': min(total_counts),\n",
    "                'max_count': max(total_counts),\n",
    "                'total_analyses': len(self.history),\n",
    "                'color_frequencies': self._calculate_color_frequencies()\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating history statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_color_frequencies(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate color frequencies across all historical results.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing color frequencies\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.history:\n",
    "                return {}\n",
    "                \n",
    "            all_colors = []\n",
    "            for result in self.history:\n",
    "                all_colors.extend(result['color_distribution'].keys())\n",
    "                \n",
    "            return dict(Counter(all_colors))\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating color frequencies: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCounterGUI:\n",
    "    \"\"\"\n",
    "    Main GUI application for M&M Counter System.\n",
    "    \n",
    "    Integrates all components:\n",
    "    - WebcamCapture for image acquisition\n",
    "    - ImageProcessor for image processing\n",
    "    - MMDetector for M&M detection\n",
    "    - ResultAnalyzer for result analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the GUI application and all components.\"\"\"\n",
    "        self.setup_logging()\n",
    "        self.setup_components()\n",
    "        self.setup_gui()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging system.\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def setup_components(self):\n",
    "        \"\"\"Initialize all system components.\"\"\"\n",
    "        try:\n",
    "            self.webcam = WebcamCapture()\n",
    "            self.processor = ImageProcessor()\n",
    "            self.detector = MMDetector()\n",
    "            self.analyzer = ResultAnalyzer()\n",
    "            \n",
    "            # Initialize state variables\n",
    "            self.current_image = None\n",
    "            self.current_results = None\n",
    "            self.is_processing = False\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing components: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Set up the graphical user interface.\"\"\"\n",
    "        try:\n",
    "            self.root = tk.Tk()\n",
    "            self.root.title(\"M&M Counter System\")\n",
    "            self.root.geometry(\"1200x800\")\n",
    "            \n",
    "            # Create main container with padding\n",
    "            self.main_container = ttk.Frame(self.root, padding=\"10\")\n",
    "            self.main_container.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            \n",
    "            # Configure grid weights\n",
    "            self.root.columnconfigure(0, weight=1)\n",
    "            self.root.rowconfigure(0, weight=1)\n",
    "            self.main_container.columnconfigure(1, weight=1)\n",
    "            self.main_container.rowconfigure(1, weight=1)\n",
    "            \n",
    "            self.setup_control_panel()\n",
    "            self.setup_image_display()\n",
    "            self.setup_results_panel()\n",
    "            self.setup_status_bar()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up GUI: {str(e)}\")\n",
    "            raise\n",
    "    def setup_control_panel(self):\n",
    "        \"\"\"Set up the control panel with buttons and options.\"\"\"\n",
    "        try:\n",
    "            # Create main control frame\n",
    "            control_frame = ttk.LabelFrame(self.main_container, text=\"Controls\", padding=\"5\")\n",
    "            control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N), padx=5, pady=5)\n",
    "            \n",
    "            # File operations\n",
    "            file_frame = ttk.LabelFrame(control_frame, text=\"File Operations\", padding=\"5\")\n",
    "            file_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(file_frame, text=\"Load Image\", \n",
    "                      command=self.load_image).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(file_frame, text=\"Save Results\", \n",
    "                      command=self.save_results).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            # Camera operations\n",
    "            camera_frame = ttk.LabelFrame(control_frame, text=\"Camera Control\", padding=\"5\")\n",
    "            camera_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(camera_frame, text=\"Start Camera\", \n",
    "                      command=self.start_camera).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(camera_frame, text=\"Capture\", \n",
    "                      command=self.capture_from_webcam).grid(row=0, column=1, padx=2)\n",
    "            ttk.Button(camera_frame, text=\"Stop Camera\", \n",
    "                      command=self.stop_camera).grid(row=0, column=2, padx=2)\n",
    "            \n",
    "            # Processing controls\n",
    "            process_frame = ttk.LabelFrame(control_frame, text=\"Processing\", padding=\"5\")\n",
    "            process_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(process_frame, text=\"Process Image\", \n",
    "                      command=self.process_image).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(process_frame, text=\"Clear\", \n",
    "                      command=self.clear_display).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            # Settings\n",
    "            settings_frame = ttk.LabelFrame(control_frame, text=\"Settings\", padding=\"5\")\n",
    "            settings_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            # Detection parameters\n",
    "            ttk.Label(settings_frame, text=\"Min Radius:\").grid(row=0, column=0, padx=2)\n",
    "            self.min_radius_var = tk.StringVar(value=str(self.detector.min_radius))\n",
    "            ttk.Entry(settings_frame, textvariable=self.min_radius_var, \n",
    "                     width=5).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            ttk.Label(settings_frame, text=\"Max Radius:\").grid(row=0, column=2, padx=2)\n",
    "            self.max_radius_var = tk.StringVar(value=str(self.detector.max_radius))\n",
    "            ttk.Entry(settings_frame, textvariable=self.max_radius_var, \n",
    "                     width=5).grid(row=0, column=3, padx=2)\n",
    "            \n",
    "            ttk.Button(settings_frame, text=\"Apply\", \n",
    "                      command=self.apply_settings).grid(row=0, column=4, padx=5)\n",
    "            \n",
    "            # Analysis options\n",
    "            analysis_frame = ttk.LabelFrame(control_frame, text=\"Analysis Options\", padding=\"5\")\n",
    "            analysis_frame.grid(row=4, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            self.show_colors_var = tk.BooleanVar(value=True)\n",
    "            ttk.Checkbutton(analysis_frame, text=\"Show Colors\", \n",
    "                           variable=self.show_colors_var).grid(row=0, column=0)\n",
    "            \n",
    "            self.show_centers_var = tk.BooleanVar(value=True)\n",
    "            ttk.Checkbutton(analysis_frame, text=\"Show Centers\", \n",
    "                           variable=self.show_centers_var).grid(row=0, column=1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up control panel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_image_display(self):\n",
    "        \"\"\"Set up the image display area.\"\"\"\n",
    "        try:\n",
    "            display_frame = ttk.LabelFrame(self.main_container, text=\"Image Display\", padding=\"5\")\n",
    "            display_frame.grid(row=0, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)\n",
    "            \n",
    "            self.image_label = ttk.Label(display_frame)\n",
    "            self.image_label.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            \n",
    "            # Configure grid weights\n",
    "            display_frame.columnconfigure(0, weight=1)\n",
    "            display_frame.rowconfigure(0, weight=1)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up image display: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_results_panel(self):\n",
    "        \"\"\"Set up the results display panel.\"\"\"\n",
    "        try:\n",
    "            results_frame = ttk.LabelFrame(self.main_container, text=\"Results\", padding=\"5\")\n",
    "            results_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)\n",
    "            \n",
    "            # Results text display with scrollbar\n",
    "            self.results_text = tk.Text(results_frame, height=10, width=40)\n",
    "            scrollbar = ttk.Scrollbar(results_frame, orient=tk.VERTICAL, \n",
    "                                    command=self.results_text.yview)\n",
    "            \n",
    "            self.results_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))\n",
    "            \n",
    "            self.results_text['yscrollcommand'] = scrollbar.set\n",
    "            \n",
    "            # Configure grid weights\n",
    "            results_frame.columnconfigure(0, weight=1)\n",
    "            results_frame.rowconfigure(0, weight=1)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up results panel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_status_bar(self):\n",
    "        \"\"\"Set up the status bar.\"\"\"\n",
    "        try:\n",
    "            self.status_var = tk.StringVar()\n",
    "            self.status_var.set(\"Ready\")\n",
    "            \n",
    "            status_bar = ttk.Label(self.main_container, textvariable=self.status_var, \n",
    "                                 relief=tk.SUNKEN)\n",
    "            status_bar.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up status bar: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def apply_settings(self):\n",
    "        \"\"\"Apply detection parameter settings.\"\"\"\n",
    "        try:\n",
    "            # Update detector parameters\n",
    "            min_radius = int(self.min_radius_var.get())\n",
    "            max_radius = int(self.max_radius_var.get())\n",
    "            \n",
    "            self.detector.adjust_detection_params(\n",
    "                min_radius=min_radius,\n",
    "                max_radius=max_radius\n",
    "            )\n",
    "            \n",
    "            self.status_var.set(\"Detection parameters updated\")\n",
    "            \n",
    "            # Reprocess current image if available\n",
    "            if self.current_image is not None:\n",
    "                self.process_image()\n",
    "                \n",
    "        except ValueError as e:\n",
    "            messagebox.showerror(\"Error\", \"Invalid parameter values\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error applying settings: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to apply settings: {str(e)}\")\n",
    "\n",
    "    def load_image(self):\n",
    "        \"\"\"Load image from file.\"\"\"\n",
    "        try:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=\"Select Image\",\n",
    "                filetypes=[\n",
    "                    (\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.gif *.tiff\"),\n",
    "                    (\"All files\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                self.current_image = cv2.imread(file_path)\n",
    "                if self.current_image is None:\n",
    "                    raise ValueError(\"Failed to load image\")\n",
    "                    \n",
    "                self.display_image(self.current_image)\n",
    "                self.status_var.set(f\"Loaded image: {os.path.basename(file_path)}\")\n",
    "                self.logger.info(f\"Loaded image from {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading image: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load image: {str(e)}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save current results to file.\"\"\"\n",
    "        try:\n",
    "            if self.current_results is None:\n",
    "                messagebox.showwarning(\"Warning\", \"No results to save\")\n",
    "                return\n",
    "                \n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=\".json\",\n",
    "                filetypes=[(\"JSON files\", \"*.json\")]\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                self.analyzer.save_results(self.current_results, file_path)\n",
    "                self.status_var.set(f\"Results saved to {os.path.basename(file_path)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving results: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to save results: {str(e)}\")\n",
    "\n",
    "    def start_camera(self):\n",
    "        \"\"\"Initialize and start the webcam preview.\"\"\"\n",
    "        try:\n",
    "            if self.webcam.initialize_camera():\n",
    "                self.preview_window = tk.Toplevel(self.root)\n",
    "                self.preview_window.title(\"Camera Preview\")\n",
    "                self.preview_label = ttk.Label(self.preview_window)\n",
    "                self.preview_label.pack()\n",
    "                \n",
    "                self.update_preview()\n",
    "                self.status_var.set(\"Camera preview active\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Failed to initialize camera\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error starting camera: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to start camera: {str(e)}\")\n",
    "\n",
    "    def update_preview(self):\n",
    "        \"\"\"Update the camera preview.\"\"\"\n",
    "        if hasattr(self, 'preview_window'):\n",
    "            frame = self.webcam.capture_frame()\n",
    "            if frame is not None:\n",
    "                self.display_image(frame, preview=True)\n",
    "                self.root.after(10, self.update_preview)\n",
    "\n",
    "    def capture_from_webcam(self):\n",
    "        \"\"\"Capture image from webcam.\"\"\"\n",
    "        try:\n",
    "            frame = self.webcam.capture_frame()\n",
    "            if frame is not None:\n",
    "                self.current_image = frame\n",
    "                self.display_image(frame)\n",
    "                self.status_var.set(\"Image captured from webcam\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Failed to capture image\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error capturing from webcam: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to capture image: {str(e)}\")\n",
    "\n",
    "    def stop_camera(self):\n",
    "        \"\"\"Stop the webcam preview and release resources.\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'preview_window'):\n",
    "                self.preview_window.destroy()\n",
    "                delattr(self, 'preview_window')\n",
    "                \n",
    "            self.webcam.release()\n",
    "            self.status_var.set(\"Camera stopped\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error stopping camera: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to stop camera: {str(e)}\")\n",
    "\n",
    "    def process_image(self):\n",
    "        \"\"\"Process the current image and detect M&Ms.\"\"\"\n",
    "        try:\n",
    "            if self.current_image is None:\n",
    "                messagebox.showwarning(\"Warning\", \"No image loaded\")\n",
    "                return\n",
    "                \n",
    "            if self.is_processing:\n",
    "                return\n",
    "                \n",
    "            self.is_processing = True\n",
    "            self.status_var.set(\"Processing image...\")\n",
    "            \n",
    "            # Process image\n",
    "            gray, hsv, blurred = self.processor.process_for_detection(self.current_image)\n",
    "            \n",
    "            # Detect M&Ms\n",
    "            circles, colors = self.detector.process_image(gray, hsv)\n",
    "            \n",
    "            if len(circles) == 0:\n",
    "                self.status_var.set(\"No M&Ms detected\")\n",
    "                return\n",
    "                \n",
    "            # Analyze results\n",
    "            self.current_results = self.analyzer.analyze_results(circles, colors)\n",
    "            \n",
    "            # Display results\n",
    "            self.display_results(self.current_results)\n",
    "            \n",
    "            # Display processed image\n",
    "            result_image = self.detector.draw_results(self.current_image, circles, colors)\n",
    "            self.display_image(result_image)\n",
    "            \n",
    "            self.status_var.set(f\"Detected {len(circles)} M&Ms\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing image: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to process image: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            self.is_processing = False\n",
    "\n",
    "    def display_image(self, image: np.ndarray, preview: bool = False):\n",
    "        \"\"\"Display image in GUI.\"\"\"\n",
    "        try:\n",
    "            # Convert BGR to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            pil_image = Image.fromarray(image_rgb)\n",
    "            \n",
    "            # Resize if needed\n",
    "            display_size = (800, 600)\n",
    "            pil_image.thumbnail(display_size, Image.LANCZOS)\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            photo = ImageTk.PhotoImage(pil_image)\n",
    "            \n",
    "            # Update display\n",
    "            if preview:\n",
    "                self.preview_label.configure(image=photo)\n",
    "                self.preview_label.image = photo\n",
    "            else:\n",
    "                self.image_label.configure(image=photo)\n",
    "                self.image_label.image = photo\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error displaying image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def display_results(self, results: Dict):\n",
    "        \"\"\"Display analysis results in GUI.\"\"\"\n",
    "        try:\n",
    "            report = self.analyzer.generate_report(results)\n",
    "            self.results_text.delete(1.0, tk.END)\n",
    "            self.results_text.insert(tk.END, report)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error displaying results: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to display results: {str(e)}\")\n",
    "\n",
    "    def clear_display(self):\n",
    "        \"\"\"Clear the current image and results.\"\"\"\n",
    "        self.current_image = None\n",
    "        self.current_results = None\n",
    "        self.image_label.configure(image='')\n",
    "        self.results_text.delete(1.0, tk.END)\n",
    "        self.status_var.set(\"Display cleared\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Start the GUI application.\"\"\"\n",
    "        try:\n",
    "            self.root.mainloop()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Application error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Cleanup resources on deletion.\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'webcam'):\n",
    "                self.webcam.release()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the application\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        app = MMCounterGUI()\n",
    "        app.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting application: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *** \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Efficient inventory management in warehouse operations, yet many businesses still rely on manual methods that are time-consuming, error-prone, and disruptive to customer service. Automated inventory systems, while effective, are often prohibitively expensive or difficult to adapt to specific needs. This project aims to create a cost-effective solution by improving the provided Python code for counting M&M candies. We aim to develop a functional counting system , debugging and enhancing computer the current code.\n",
    "\n",
    "This topic was chosen because it represents a critical problem in real-world inventory tracking while being accessible enough to demonstrate practical applications. The goal is to refine the provided OpenCV-based code into a robust and adaptable inventory counting solution. This requires resolving specific limitations, such as dependence on ideal lighting conditions, assumptions about object shape, and errors in color classification. The improvements aim to create a versatile system that can be extended to other inventory use cases, such as counting objects of varying shapes and colors.\n",
    "\n",
    "The project will be implemented by first analyzing the current code to identify its specific weaknesses. Initial tests with sample images will help quantify errors in detection and classification. Improvements will then be introduced iteratively, starting with lighting normalization techniques, such as adaptive histogram equalization, to reduce the impact of lighting inconsistencies. The circle detection algorithm will be replaced with contour-based detection methods to handle overlapping and irregularly shaped m&ms. Colour classification will be enhanced by transforming images to alternative color spaces, like HSV or LAB, which are less sensitive to lighting variations, and clustering techniques will be applied to improve segmentation accuracy. Additionally, the code will be edited for better readability, optimization, and adaptability to other object types.\n",
    "\n",
    "By the end of this project, the enhanced code will not only function effectively for the test case of M&M candies but also serve as a foundation for broader applications in inventory systems. The improvements and results will be documented thoroughly including sample tests, performance metrics, and setup instructions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Methods\n",
    "\n",
    "The sample code provided for the M&M Counter System was has been analyzed, debugged, and modified to enhance its functionality, efficiency, and reliability. These modifications were implemented with specific objectives in mind to ensure robust performance in detecting and classifying objects. B\n",
    "\n",
    "To improve detection and classification accuracy, several changes were introduced. The HSV ranges were expanded and fine-tuned to ensure better recognition of a broader spectrum of candy colours. A new colour category for \"purple\" was added, and thresholds for orange and brown were optimized to address the challenges posed by varying lighting conditions. To address inconsistencies in image brightness and contrast, a preprocessing function utilizing adaptive histogram equalization (CLAHE) was introduced. Additionally, sharpening and denoising techniques were incorporated into the pipeline. For example, the sharpening kernel np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) was applied to enhance image clarity, and non-local means denoising helped reduce noise without compromising edge details.\n",
    "\n",
    "Circle detection was another focus area. The system was updated to include dynamic parameter adjustments for the Hough Circle Transform. Parameters such as min_radius, max_radius, param1, and param2 could now be dynamically modified through the GUI. This allowed real-time experimentation to optimize circle detection. Moreover, a stricter validation mechanism for detected circle radii was implemented to filter out false positives, ensuring more accurate results.\n",
    "\n",
    "User experience was significantly improved through enhancements to the graphical user interface (GUI). New buttons and controls were added to facilitate image capture, file loading, and result saving. For example, the Load Image button utilized the filedialog.askopenfilename method to load images seamlessly. The camera preview feature was enhanced for real-time responsiveness, ensuring that updates were rendered dynamically during operations.\n",
    "\n",
    "Comprehensive analysis and reporting capabilities were also introduced. The system now calculates spatial statistics, such as density and average spacing, and provides confidence metrics for both detection and colour classification. These results were made accessible through automated report generation, exporting detailed analysis to JSON format for further review. For instance, the generate_report function compiled findings into a formatted string, while the save_results method saved results as JSON files.\n",
    "\n",
    "To streamline the image processing pipeline, the code was modularized. Functions were clearly defined, separating steps such as LAB colour space conversion and adaptive thresholding for segmentation. This modular design made the pipeline easier to debug and extend. For instance, preprocessing was handled in the process_for_detection method, which combined enhancement, denoising, and brightness adjustment steps.\n",
    "\n",
    "Performance optimization was prioritized to ensure real-time operation. Frame-rate monitoring was integrated into the system, enabling real-time evaluation of camera performance. Error handling was improved to manage invalid inputs and hardware failures gracefully. For example, exceptions raised during camera initialization or image capture were logged and displayed via error messages. Logging was extensively used to track system performance and facilitate debugging.\n",
    "\n",
    "Modernization efforts were made to ensure the system's scalability and compatibility with future advancements. The pipeline was updated to support the detection of other objects, such as lumber or fruits, by parameterizing color ranges and detection thresholds. Preparations were also made for integrating deep learning-based object detection models like YOLO or Mask R-CNN. These updates positioned the system as a versatile solution for inventory counting across various domains.\n",
    "\n",
    "By implementing these modifications, the system transcended its original capabilities, transforming into a robust and versatile tool suitable for real-world applications. These enhancements not only made the system functional but also equipped it with the adaptability needed for dynamic environments, demonstrating its potential in fields such as retail inventory management and industrial automation.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Results\n",
    "\n",
    " Write as a user manual explaining how to use your code. Include:\n",
    "  * Sample test images\n",
    "  * A set of documented tests\n",
    "  * Results in tables and graphs\n",
    "    * Consider using [numpy](https://numpy.org/) for any mathematical calculation including statistics\n",
    "    * Consider using [matplotlib](https://matplotlib.org/) for graphs and plots.\n",
    "    * The combination of [numpy](https://numpy.org/) and [matplotlib](https://matplotlib.org/) simulates the Matlab environment and the syntax are almost identical!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Discussion\n",
    "\n",
    "  * Why you chose your approach\n",
    "  * What was needed to make it work\n",
    "  * If issues arose, document the reasons (**It is acceptable if your program doesn't work perfectly** as long as you investigate why)\n",
    "  * Potential societal/economic implications and impact\n",
    "\n",
    "\n",
    "The chosen approach focused on improving and extending the provided sample code due to its accessibility and potential for customization. The OpenCV-based implementation served as a strong foundation for understanding traditional computer vision techniques while allowing for iterative enhancement. The decision to start with the sample code enabled the team to address specific weaknesses systematically, such as lighting inconsistencies, inaccurate circle detection, and limited color classification.\n",
    "\n",
    "**Requirements for Success**\n",
    "\n",
    "To make the system work effectively, several key components were required. First, robust preprocessing techniques were essential to normalize lighting and enhance image clarity. This included the use of CLAHE for brightness equalization and Gaussian blurring for noise reduction. Dynamic parameter adjustments for the Hough Circle Transform were introduced to optimize detection across different test cases. Additionally, the HSV and LAB colour spaces were employed to improve color classification accuracy under varying conditions. A modular pipeline ensured that individual components could be tested and debugged independently, contributing to overall system reliability.\n",
    "\n",
    "**Challenges and Issues**\n",
    "\n",
    "Several challenges arose during the project. Lighting variability in the test images often caused inconsistencies in color detection, necessitating extensive adjustments to the preprocessing pipeline. Overlapping M&Ms posed another significant challenge, as the Hough Circle Transform struggled with irregular shapes. To address this, validation mechanisms were implemented to filter out false positives. GUI responsiveness was initially a concern, particularly when processing high-resolution images in real-time. Optimizations were made to streamline operations, but occasional lag persisted under heavy computational loads. These challenges highlighted the limitations of traditional computer vision methods and suggested opportunities for integrating machine learning techniques in future iterations.\n",
    "\n",
    "**Societal and Economic Implications**\n",
    "\n",
    "The development of cost-effective inventory management systems has societal and economic implications. By providing a low-cost alternative to expensive commercial systems, this project demonstrates the potential for democratizing technology in small and medium-sized enterprises. Enhanced inventory tracking reduces waste, improves operational efficiency, and supports sustainable business practices. Furthermore, the adaptability of the system to other use cases, such as agricultural monitoring or manufacturing, underscores its broader applicability. From a societal perspective, the project showcases how accessible technology can empower businesses and individuals to address everyday challenges effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***\n",
    " \n",
    "## Conclusion\n",
    "\n",
    "This project offered an opportunity to address a real-world problem in inventory management using computer vision techniques. By working through the challenges of debugging and enhancing the sample code, the team gained valuable experience in image preprocessing, object detection, and system optimization. The iterative development process reinforced the importance of analyzing weaknesses and systematically improving both technical functionality and user accessibility.\n",
    "\n",
    "One key takeaway was the significance of robust preprocessing methods, such as adaptive histogram equalization and colour space transformations, in mitigating the impact of environmental variability. This was particularly evident in overcoming challenges related to lighting and object overlap. Additionally, the implementation of a dynamic, user-friendly GUI highlighted the balance between technical complexity and usability, ensuring the system could be deployed in practical applications.\n",
    "\n",
    " This project bridged the gap between theoretical knowledge and practical application, providing a comprehensive understanding of computer vision's capabilities in solving industry-relevant problems. The skills developed and insights gained lay a strong foundation for future projects in inventory management and related fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***\n",
    " \n",
    "## Bibliography\n",
    "\n",
    " Provide a list of references relevant to your report. For example, if you use a publicly available ML model, provide a citation/reference to the original paper and the URL where you downloaded the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
