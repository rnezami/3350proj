{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b>Western University</b></center>\n",
    "## <center><b>Faculty of Engineering</b></center>\n",
    "## <center><b>Department of Electrical and Computer Engineering</b></center>\n",
    "\n",
    "# <center><b>AISE 3350A FW24: Cyber-Physical Systems Theory</b></center>\n",
    "\n",
    "<center>September 27, 2024</center>\n",
    "\n",
    "Instructor: <a href=\"mailto:echen29@uwo.ca?Subject=AISE3350A%20Week%204\">Prof. Elvis Chen, Ph.D., LEL</a>\n",
    "- Department of Electrical and Computer Engineering\n",
    "- Robarts Research Institute\n",
    "- School of Biomedical Engineering\n",
    "- Department of Medical Biophysics\n",
    "- Department of Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-Enhanced Candy Inventory System Group Project\n",
    "\n",
    "***\n",
    "\n",
    "## Table of Contents\n",
    "- [Due Date](#due-date)\n",
    "- [Project Overview](#project-overview)\n",
    "- [Learning Objectives](#learning-objectives)\n",
    "- [Evaluation Criteria](#evaluation-criteria)\n",
    "- [What do Submit](#what-to-submit)\n",
    "- [Sample Code](#sample-code)\n",
    "- [Notes to Sample Code](#notes-to-sample-code)\n",
    "\n",
    "***\n",
    "## Due Date\n",
    "\n",
    "December 6, 2024\n",
    "\n",
    "- The OWL submission site will remain open until 11:55 PM December 13, 2024 for accommodations, without penalty.\n",
    "- Submissions received after December 13, 2024 will incur a penalty of 10% per day.\n",
    "\n",
    "This project is to be submitted as a Jupyter Notebook Document, with Python executable, on OWL.\n",
    "\n",
    "***\n",
    "## Project Overview\n",
    "\n",
    "### Part 1: Background and Motivation\n",
    "\n",
    "In retail and warehouse management, efficient inventory tracking remains a crucial challenge. Store managers need quick, accurate counts of stock - from lumber piles in hardware stores to soft drinks on grocery shelves. Manual counting is time-consuming, error-prone, and diverts staff from customer service.\n",
    "\n",
    "While commercial automated counting systems exist, they're often expensive and inflexible. This project explores developing a cost-effective counting system using a familiar test case: M&M candies. Though simplified, this scenario presents many of the same challenges found in industrial applications: varied lighting, object detection, colour classification, and system integration.\n",
    "\n",
    "![Object counting scenario](https://cdn.labellerr.com/1%20Object%20Counting%20and%20Sorting/Object%20counting.webp)\n",
    "[image courtesy](https://www.labellerr.com/blog/object-counting-and-sorting-using-computer-vision/)\n",
    "\n",
    "### Part 2: Learning Approach and Technical Objectives\n",
    "\n",
    "**A sample Python code is provided at the end of this Jupyter Notebook Document.**\n",
    "\n",
    "This project offers multiple implementation paths, each with distinct learning opportunities:\n",
    "\n",
    "#### Traditional Computer Vision\n",
    "\n",
    "The provided sample code demonstrates a classical approach:\n",
    "* Uses OpenCV-based implementation\n",
    "* Relies on circle detection algorithms\n",
    "* Performs colour space analysis\n",
    "* Requires debugging and optimization\n",
    "* Teaches fundamental computer vision concepts\n",
    "\n",
    "#### Modern Machine Learning Approaches\n",
    "\n",
    "While the sample code, **which is not fully debugged**, demonstrates a feasible approach to inventory counting, it relies on specific assumptions about the problem:\n",
    "\n",
    "* The candies appear as circular objects in a photo\n",
    "* The candies only come in predefined colours\n",
    "\n",
    "**However**, the traditional approach often fails because:\n",
    "* Varying lighting conditions affect colour detection accuracy\n",
    "* Limited generalization: the program cannot be easily adapted to count other objects (e.g., 4x4 lumber)\n",
    "\n",
    "You may choose one of two paths to complete this project:\n",
    "\n",
    "1. Debug and enhance the sample code to make it fully functional\n",
    "2. Replace the `class MMDetector`, which currently relies on traditional computer-vision (CV) techniques, with machine-learning (ML) techniques\n",
    "3. You are free to modify any part of the sample code as you see fit.\n",
    "\n",
    "**Note**: Your choice of approach will not affect your mark - both paths are equally valid.\n",
    "\n",
    "*If you choose the ML approach*, consider these suggestions:\n",
    "\n",
    "##### 1. Object Detection Networks\n",
    "* Implementation using [YOLO](https://arxiv.org/abs/2402.13616) or [Faster R-CNN](https://paperswithcode.com/method/faster-r-cnn)\n",
    "* Benefits: Robust to shape variations\n",
    "* Challenges: Requires training data\n",
    "* Good for detecting multiple objects simultaneously\n",
    "\n",
    "##### 2. Segment Anything Model (SAM)\n",
    "* [SAM](https://paperswithcode.com/method/sam)\n",
    "* Zero-shot segmentation capabilities\n",
    "* Handles irregular shapes and lighting variations\n",
    "* Can be combined with custom colour classifier\n",
    "* No training data required for basic segmentation\n",
    "* Prompt-based object identification\n",
    "\n",
    "##### 3. Custom CNN Solutions\n",
    "* End-to-end learning approach\n",
    "* Combined detection and classification\n",
    "* Transfer learning possibilities\n",
    "* Can be optimized for specific use case\n",
    "\n",
    "#### Implementation Considerations\n",
    "\n",
    "When choosing an approach, consider:\n",
    "* Accuracy vs. processing speed trade-offs\n",
    "* Implementation complexity and development time\n",
    "* Resource requirements (compute, memory, storage)\n",
    "* Real-world robustness and reliability\n",
    "* Available development time\n",
    "* Hardware limitations\n",
    "\n",
    "This project emphasizes practical problem-solving while building expertise in modern computer vision and machine learning techniques applicable to industrial automation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Students will:\n",
    "- [ ] Apply computer vision/ML concepts to real-world problems, or\n",
    "- [ ] Debug/enhance the sample code provided below to make it fully functional\n",
    "- [ ] Develop system integration skills\n",
    "- [ ] Practice software engineering principles\n",
    "- [ ] Handle real-world variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Evaluation Criteria\n",
    "This project uses Graduate Attributes (GAs) for assessment. Please note:\n",
    "\n",
    "- This project is worth 25% of your final mark\n",
    "- Total marks: 30 points\n",
    "- Each Graduate Attribute (GA) is evaluated on a scale of 1 to 4\n",
    "- Evaluation focuses on your **understanding** and **effort** in problem-solving\n",
    "- Program accuracy is not the primary evaluation criterion, though consistent good performance may earn bonus marks\n",
    "- Pay attention to the following rubric and specification of the project report in order to understand what is asked of you.\n",
    "\n",
    "\n",
    "| Graduate Attribute | Unacceptable (1) | Below Expectations (2) | Meets Expectations (3) | Exceeds Expectations (4) |\n",
    "|-------------------|-------------------|----------------------|----------------------|-------------------------|\n",
    "| **KB4 - Specialized Engineering Knowledge** | Unable to articulate specialized discipline-specific engineering knowledge | Recollection of specialized discipline-specific engineering knowledge is inaccurate â€“ fundamentals clearly wrong | Competent in the essential aspects of discipline-specific engineering knowledge | Meets expectations plus: Recognizes nuances of discipline-specific engineering knowledge |\n",
    "| **ET1 - Engineering Tools** | Applicability of an ET to a problem not recognized: ET not used! | Improper ET selected because underlying mathematical AND/OR engineering fundamentals not recognized | ET selection justified by comprehension of the underlying mathematical AND/OR engineering fundamentals | Meets expectation, plus: Limitations of the selected tool are identified and assessed |\n",
    "| **CS3 - Written Communication** | Technical language is unclear, with much jargon, presentation is incoherent, spelling grammar and syntax mostly incorrect, graphical tools not used where appropriate | Technical language is sometimes unclear or inappropriate to the audience, ideas and arguments are unpersuasive; spelling grammar and syntax interfere with understanding; graphical tools used but only partly effective | Technical language is clear, and appropriate to the audience, ideas are persuasive, spelling, grammar and syntax are mostly correct, graphical tools are used effectively | Meets expectations plus: Written document is sufficiently engaging to be understood and interesting to readers from other disciplines |\n",
    "| **I3 - Data Analysis** | No meaningful analysis of data, leading to invalid conclusions | Conclusions are not justified by the data analysis presented OR experimental error and its impact not quantified | Conclusions justified by appropriate data analysis AND quantification of experimental error and its impact | Meets expectations, plus: Conclusions are framed in the context of prior knowledge and recommendations for future work are provided |\n",
    "| **IESE1 - Societal Impact** | No awareness of impact of engineering on economic aspects of society | Unable to analyse effectively the impact of engineering on the society and environment | Able to quantify accurately the impact of engineering on the society and environment | Meets expectations plus: Analysis takes into account the uncertainty of prediction of interaction with society and environment |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## What to Submit\n",
    "\n",
    "Your project will be evaluated through a Project Report submitted as a Jupyter Notebook document. Similar to Assignment 1, you will submit a Project Report, but this notebook must also contain **complete, executable Python code** for the instructor to verify your implementation.\n",
    "\n",
    "### Project Submission Requirements\n",
    "\n",
    "The Project Report must include:\n",
    "\n",
    "1. A comprehensive written report documenting your implementation\n",
    "2. Complete, executable Python code that demonstrates your solution\n",
    "   - Code must be properly commented and organized\n",
    "   - All dependencies must be clearly listed\n",
    "   - Include setup/installation instructions if needed\n",
    "\n",
    "Your notebook should enable the instructor to:\n",
    "* Understand your technical approach\n",
    "* Run your implementation\n",
    "* Verify your results\n",
    "* Assess your learning outcomes\n",
    "\n",
    "The format follows Assignment 1's structure but requires both documentation and functional code.\n",
    "\n",
    "### Written Report Format\n",
    "\n",
    "Your project report should contain these sections:\n",
    "\n",
    "- **Introduction**: Detail the motivation and background context explaining why this counting topic was chosen\n",
    "- **Methods**: Explain how you modified the sample code. If using ML, describe which model was chosen (and why), and how it was integrated into the existing code\n",
    "- **Results**: Write as a user manual explaining how to use your code. Include:\n",
    "  * Sample test images\n",
    "  * A set of documented tests\n",
    "  * Results in tables and graphs\n",
    "    * Consider using [numpy](https://numpy.org/) for any mathematical calculation including statistics\n",
    "    * Consider using [matplotlib](https://matplotlib.org/) for graphs and plots.\n",
    "    * The combination of [numpy](https://numpy.org/) and [matplotlib](https://matplotlib.org/) simulates the Matlab environment and the syntax are almost identical!\n",
    "- **Discussion**: Explain:\n",
    "  * Why you chose your approach\n",
    "  * What was needed to make it work\n",
    "  * If issues arose, document the reasons (**It is acceptable if your program doesn't work perfectly** as long as you investigate why)\n",
    "  * Potential societal/economic implications and impact\n",
    "- **Conclusion**: Detail what you learned\n",
    "- **Bibliography**: Provide a list of references relevant to your report. For example, if you use a publicly available ML model, provide a citation/reference to the original paper and the URL where you downloaded the model.\n",
    "\n",
    "\n",
    "\n",
    "### What to Upload to OWL\n",
    "\n",
    "Each group should upload to OWL the following:\n",
    "- Complete Jupyter Notebook Document containing:\n",
    "  * Written Project Report\n",
    "  * Python executable code\n",
    "- A set of five (5) sample images\n",
    "  * Your program should allow the instructor to load each of the 5 images (individually) and verify the efficacy of your program by executing the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for the M&M Counter System\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebcamCapture:\n",
    "    \"\"\"\n",
    "    Handles webcam operations including initialization, capture, and resource management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, camera_id: int = 0):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self.camera = None\n",
    "        self.is_capturing = False\n",
    "        self.camera_id = camera_id\n",
    "        \n",
    "        # Default camera settings\n",
    "        self.frame_width = 1280\n",
    "        self.frame_height = 720\n",
    "        self.fps = 30\n",
    "        \n",
    "        # Camera parameters\n",
    "        self.camera_settings = {\n",
    "            cv2.CAP_PROP_FRAME_WIDTH: self.frame_width,\n",
    "            cv2.CAP_PROP_FRAME_HEIGHT: self.frame_height,\n",
    "            cv2.CAP_PROP_FPS: self.fps,\n",
    "            cv2.CAP_PROP_AUTOFOCUS: 1,\n",
    "            cv2.CAP_PROP_BRIGHTNESS: 128,\n",
    "            cv2.CAP_PROP_CONTRAST: 128,\n",
    "            cv2.CAP_PROP_SATURATION: 128\n",
    "        }\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.frame_count = 0\n",
    "        self.start_time = None\n",
    "        \n",
    "    def initialize_camera(self, camera_id: Optional[int] = None) -> bool:\n",
    "        try:\n",
    "            if camera_id is not None:\n",
    "                self.camera_id = camera_id\n",
    "                \n",
    "            self.camera = cv2.VideoCapture(self.camera_id)\n",
    "            \n",
    "            if not self.camera.isOpened():\n",
    "                self.logger.error(f\"Failed to open camera {self.camera_id}\")\n",
    "                return False\n",
    "                \n",
    "            for prop, value in self.camera_settings.items():\n",
    "                self.camera.set(prop, value)\n",
    "                \n",
    "            actual_width = self.camera.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            actual_height = self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "            \n",
    "            self.logger.info(f\"Camera initialized: {actual_width}x{actual_height}\")\n",
    "            \n",
    "            self.frame_count = 0\n",
    "            self.start_time = time.time()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing camera: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def capture_frame(self) -> Optional[np.ndarray]:\n",
    "        if self.camera is None:\n",
    "            self.logger.error(\"Camera not initialized\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            ret, frame = self.camera.read()\n",
    "            \n",
    "            if ret:\n",
    "                self.frame_count += 1\n",
    "                return frame\n",
    "            else:\n",
    "                self.logger.error(\"Failed to capture frame\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error capturing frame: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def get_fps(self) -> float:\n",
    "        if self.start_time is None or self.frame_count == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return self.frame_count / elapsed_time if elapsed_time > 0 else 0.0\n",
    "        \n",
    "    def get_camera_properties(self) -> Dict:\n",
    "        if self.camera is None:\n",
    "            return {}\n",
    "            \n",
    "        properties = {\n",
    "            'width': self.camera.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "            'height': self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT),\n",
    "            'fps': self.camera.get(cv2.CAP_PROP_FPS),\n",
    "            'brightness': self.camera.get(cv2.CAP_PROP_BRIGHTNESS),\n",
    "            'contrast': self.camera.get(cv2.CAP_PROP_CONTRAST),\n",
    "            'saturation': self.camera.get(cv2.CAP_PROP_SATURATION),\n",
    "            'auto_focus': self.camera.get(cv2.CAP_PROP_AUTOFOCUS),\n",
    "            'actual_fps': self.get_fps()\n",
    "        }\n",
    "        return properties\n",
    "        \n",
    "    def set_camera_property(self, property_id: int, value: float) -> bool:\n",
    "        if self.camera is None:\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            return self.camera.set(property_id, value)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting camera property: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def set_resolution(self, width: int, height: int) -> bool:\n",
    "        try:\n",
    "            success = True\n",
    "            success &= self.set_camera_property(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "            success &= self.set_camera_property(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "            \n",
    "            if success:\n",
    "                self.frame_width = width\n",
    "                self.frame_height = height\n",
    "                self.logger.info(f\"Resolution set to {width}x{height}\")\n",
    "            \n",
    "            return success\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting resolution: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def start_preview(self, window_name: str = \"Camera Preview\") -> None:\n",
    "        if self.camera is None:\n",
    "            self.logger.error(\"Camera not initialized\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            self.is_capturing = True\n",
    "            \n",
    "            while self.is_capturing:\n",
    "                frame = self.capture_frame()\n",
    "                \n",
    "                if frame is not None:\n",
    "                    cv2.imshow(window_name, frame)\n",
    "                    \n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                        \n",
    "            cv2.destroyWindow(window_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in preview: {str(e)}\")\n",
    "            self.is_capturing = False\n",
    "            \n",
    "    def stop_preview(self) -> None:\n",
    "        self.is_capturing = False\n",
    "        \n",
    "    def release(self) -> None:\n",
    "        try:\n",
    "            if self.camera is not None:\n",
    "                self.camera.release()\n",
    "                self.camera = None\n",
    "                self.is_capturing = False\n",
    "                self.logger.info(\"Camera resources released\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error releasing camera: {str(e)}\")\n",
    "            \n",
    "    def __del__(self):\n",
    "        self.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Handles image processing operations for M&M detection.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        blur_kernel_size: Size of Gaussian blur kernel\n",
    "        adaptive_block_size: Block size for adaptive thresholding\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Processing parameters\n",
    "        self.blur_kernel_size = (7, 7)\n",
    "        self.adaptive_block_size = 11\n",
    "        self.clahe_parameters = {\n",
    "            'clip_limit': 3.0,\n",
    "            'tile_grid_size': (8, 8)\n",
    "        }\n",
    "        \n",
    "    def preprocess_image(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocess image for M&M detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image in BGR format\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - Grayscale processed image\n",
    "                - HSV image\n",
    "                - Blurred image\n",
    "                \n",
    "        Raises:\n",
    "            ValueError: If input image is None or empty\n",
    "            Exception: For other processing errors\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if image is None or image.size == 0:\n",
    "                raise ValueError(\"Invalid input image\")\n",
    "                \n",
    "            # Convert to HSV for better color detection\n",
    "            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            # Apply Gaussian blur to reduce noise\n",
    "            blurred = cv2.GaussianBlur(image, self.blur_kernel_size, 0)\n",
    "            \n",
    "            # Convert blurred image to grayscale\n",
    "            gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            return gray, hsv, blurred\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in preprocessing: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def enhance_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Enhance image quality for better detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create a copy of the input image\n",
    "            enhanced = image.copy()\n",
    "            \n",
    "            # Convert to LAB color space\n",
    "            lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)\n",
    "            \n",
    "            # Split the LAB image into L, A, and B channels\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE to L channel\n",
    "            clahe = cv2.createCLAHE(\n",
    "                clipLimit=self.clahe_parameters['clip_limit'],\n",
    "                tileGridSize=self.clahe_parameters['tile_grid_size']\n",
    "            )\n",
    "            cl = clahe.apply(l)\n",
    "            \n",
    "            # Merge the CLAHE enhanced L-channel back with A and B channels\n",
    "            limg = cv2.merge((cl, a, b))\n",
    "            \n",
    "            # Convert back to BGR color space\n",
    "            enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "            \n",
    "            return enhanced\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in image enhancement: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def adjust_brightness_contrast(self, image: np.ndarray, \n",
    "                                 alpha: float = 1.0, \n",
    "                                 beta: int = 0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Adjust image brightness and contrast.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            alpha: Contrast control (1.0-3.0)\n",
    "            beta: Brightness control (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            Adjusted image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate parameters\n",
    "            alpha = max(0.0, min(3.0, alpha))\n",
    "            beta = max(0, min(100, beta))\n",
    "            \n",
    "            # Apply brightness and contrast adjustment\n",
    "            adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "            \n",
    "            return adjusted\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in brightness/contrast adjustment: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def denoise_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply denoising to the image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Denoised image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Apply non-local means denoising\n",
    "            denoised = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "            return denoised\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in denoising: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def sharpen_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply sharpening to the image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Sharpened image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create sharpening kernel\n",
    "            kernel = np.array([[-1,-1,-1],\n",
    "                             [-1, 9,-1],\n",
    "                             [-1,-1,-1]])\n",
    "            \n",
    "            # Apply sharpening\n",
    "            sharpened = cv2.filter2D(image, -1, kernel)\n",
    "            \n",
    "            return sharpened\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in sharpening: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def process_for_detection(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Complete processing pipeline for M&M detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing processed images for detection:\n",
    "                - Grayscale image\n",
    "                - HSV image\n",
    "                - Blurred image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Enhance image\n",
    "            enhanced = self.enhance_image(image)\n",
    "            \n",
    "            # Denoise\n",
    "            denoised = self.denoise_image(enhanced)\n",
    "            \n",
    "            # Adjust brightness and contrast\n",
    "            adjusted = self.adjust_brightness_contrast(denoised, 1.2, 10)\n",
    "            \n",
    "            # Get processed images\n",
    "            gray, hsv, blurred = self.preprocess_image(adjusted)\n",
    "            \n",
    "            return gray, hsv, blurred\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in detection processing: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def get_processing_parameters(self) -> dict:\n",
    "        \"\"\"\n",
    "        Get current processing parameters.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of current processing parameters\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'blur_kernel_size': self.blur_kernel_size,\n",
    "            'adaptive_block_size': self.adaptive_block_size,\n",
    "            'clahe_parameters': self.clahe_parameters\n",
    "        }\n",
    "        \n",
    "    def set_processing_parameters(self, \n",
    "                                blur_kernel_size: Optional[Tuple[int, int]] = None,\n",
    "                                adaptive_block_size: Optional[int] = None,\n",
    "                                clahe_clip_limit: Optional[float] = None,\n",
    "                                clahe_grid_size: Optional[Tuple[int, int]] = None) -> None:\n",
    "        \"\"\"\n",
    "        Set processing parameters.\n",
    "        \n",
    "        Args:\n",
    "            blur_kernel_size: Size of Gaussian blur kernel\n",
    "            adaptive_block_size: Block size for adaptive thresholding\n",
    "            clahe_clip_limit: Clip limit for CLAHE\n",
    "            clahe_grid_size: Grid size for CLAHE\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if blur_kernel_size is not None:\n",
    "                self.blur_kernel_size = blur_kernel_size\n",
    "            if adaptive_block_size is not None:\n",
    "                self.adaptive_block_size = adaptive_block_size\n",
    "            if clahe_clip_limit is not None:\n",
    "                self.clahe_parameters['clip_limit'] = clahe_clip_limit\n",
    "            if clahe_grid_size is not None:\n",
    "                self.clahe_parameters['tile_grid_size'] = clahe_grid_size\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting processing parameters: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMDetector:\n",
    "    \"\"\"\n",
    "    Handles M&M detection and color classification.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        min_radius: Minimum radius for M&M detection\n",
    "        max_radius: Maximum radius for M&M detection\n",
    "        min_dist: Minimum distance between detected circles\n",
    "        param1: First parameter for Hough Circle detection\n",
    "        param2: Second parameter for Hough Circle detection\n",
    "        color_ranges: HSV color ranges for M&M classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Circle detection parameters\n",
    "        self.min_radius = 10\n",
    "        self.max_radius = 30\n",
    "        self.min_dist = 20\n",
    "        self.param1 = 50  # Edge detection parameter\n",
    "        self.param2 = 30  # Circle detection parameter\n",
    "        \n",
    "        # Define color ranges in HSV format\n",
    "        self.color_ranges = {\n",
    "            'red': {\n",
    "                'lower1': np.array([0, 100, 100]),\n",
    "                'upper1': np.array([10, 255, 255]),\n",
    "                'lower2': np.array([160, 100, 100]),  # Red wraps around HSV\n",
    "                'upper2': np.array([180, 255, 255])\n",
    "            },\n",
    "            'blue': {\n",
    "                'lower': np.array([100, 100, 100]),\n",
    "                'upper': np.array([130, 255, 255])\n",
    "            },\n",
    "            'green': {\n",
    "                'lower': np.array([40, 100, 100]),\n",
    "                'upper': np.array([80, 255, 255])\n",
    "            },\n",
    "            'yellow': {\n",
    "                'lower': np.array([20, 100, 100]),\n",
    "                'upper': np.array([35, 255, 255])\n",
    "            },\n",
    "            'orange': {\n",
    "                'lower': np.array([10, 100, 100]),\n",
    "                'upper': np.array([20, 255, 255])\n",
    "            },\n",
    "            'brown': {\n",
    "                'lower': np.array([0, 100, 20]),\n",
    "                'upper': np.array([20, 255, 100])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Detection parameters history for analysis\n",
    "        self.detection_history = []\n",
    "        \n",
    "    def detect_circles(self, gray: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Detect circles in the grayscale image using Hough Circle Transform.\n",
    "        \n",
    "        Args:\n",
    "            gray: Grayscale input image\n",
    "            \n",
    "        Returns:\n",
    "            Array of detected circles (x, y, radius)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if gray is None or gray.size == 0:\n",
    "                raise ValueError(\"Invalid input image\")\n",
    "                \n",
    "            # Apply Hough Circle Transform\n",
    "            circles = cv2.HoughCircles(\n",
    "                gray,\n",
    "                cv2.HOUGH_GRADIENT,\n",
    "                dp=1,\n",
    "                minDist=self.min_dist,\n",
    "                param1=self.param1,\n",
    "                param2=self.param2,\n",
    "                minRadius=self.min_radius,\n",
    "                maxRadius=self.max_radius\n",
    "            )\n",
    "            \n",
    "            # Process detected circles\n",
    "            if circles is not None:\n",
    "                circles = np.uint16(np.around(circles))\n",
    "                \n",
    "                # Record detection parameters and results\n",
    "                self.detection_history.append({\n",
    "                    'parameters': self.get_parameters(),\n",
    "                    'circles_detected': len(circles[0])\n",
    "                })\n",
    "                \n",
    "                return circles[0]\n",
    "            return np.array([])\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in circle detection: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def identify_colors(self, hsv: np.ndarray, circles: np.ndarray) -> List[str]:\n",
    "        \"\"\"\n",
    "        Identify colors of detected M&Ms.\n",
    "        \n",
    "        Args:\n",
    "            hsv: HSV format image\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            List of color names for each detected M&M\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if hsv is None or circles is None:\n",
    "                raise ValueError(\"Invalid inputs for color identification\")\n",
    "                \n",
    "            colors = []\n",
    "            for (x, y, r) in circles:\n",
    "                # Create mask for current circle\n",
    "                mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "                cv2.circle(mask, (x, y), r-5, 255, -1)\n",
    "                \n",
    "                # Get mean color in the masked area\n",
    "                mean_color = cv2.mean(hsv, mask=mask)[:3]\n",
    "                \n",
    "                # Identify color\n",
    "                detected_color = self._classify_color(mean_color)\n",
    "                colors.append(detected_color)\n",
    "                \n",
    "            return colors\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in color identification: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _classify_color(self, hsv_color: Tuple[float, float, float]) -> str:\n",
    "        \"\"\"\n",
    "        Classify color based on HSV values.\n",
    "        \n",
    "        Args:\n",
    "            hsv_color: HSV color values\n",
    "            \n",
    "        Returns:\n",
    "            Identified color name\n",
    "        \"\"\"\n",
    "        try:\n",
    "            hsv_np = np.uint8([[list(hsv_color)]])\n",
    "            \n",
    "            # Check each color range\n",
    "            for color_name, ranges in self.color_ranges.items():\n",
    "                if color_name == 'red':\n",
    "                    # Special case for red (wraps around HSV)\n",
    "                    mask1 = cv2.inRange(hsv_np, ranges['lower1'], ranges['upper1'])\n",
    "                    mask2 = cv2.inRange(hsv_np, ranges['lower2'], ranges['upper2'])\n",
    "                    if mask1.any() or mask2.any():\n",
    "                        return color_name\n",
    "                else:\n",
    "                    mask = cv2.inRange(hsv_np, ranges['lower'], ranges['upper'])\n",
    "                    if mask.any():\n",
    "                        return color_name\n",
    "                        \n",
    "            return 'unknown'\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in color classification: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def adjust_detection_params(self, min_radius: Optional[int] = None,\n",
    "                              max_radius: Optional[int] = None,\n",
    "                              min_dist: Optional[int] = None,\n",
    "                              param1: Optional[int] = None,\n",
    "                              param2: Optional[int] = None) -> None:\n",
    "        \"\"\"\n",
    "        Adjust circle detection parameters.\n",
    "        \n",
    "        Args:\n",
    "            min_radius: Minimum circle radius\n",
    "            max_radius: Maximum circle radius\n",
    "            min_dist: Minimum distance between circles\n",
    "            param1: Edge detection parameter\n",
    "            param2: Circle detection parameter\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if min_radius is not None:\n",
    "                self.min_radius = max(1, min_radius)\n",
    "            if max_radius is not None:\n",
    "                self.max_radius = max(self.min_radius, max_radius)\n",
    "            if min_dist is not None:\n",
    "                self.min_dist = max(1, min_dist)\n",
    "            if param1 is not None:\n",
    "                self.param1 = max(1, param1)\n",
    "            if param2 is not None:\n",
    "                self.param2 = max(1, param2)\n",
    "                \n",
    "            self.logger.info(\"Detection parameters adjusted: \" + \n",
    "                           f\"min_radius={self.min_radius}, \" +\n",
    "                           f\"max_radius={self.max_radius}, \" +\n",
    "                           f\"min_dist={self.min_dist}, \" +\n",
    "                           f\"param1={self.param1}, \" +\n",
    "                           f\"param2={self.param2}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error adjusting detection parameters: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def get_parameters(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get current detection parameters.\n",
    "        \n",
    "        Returns:\n",
    "            Current parameter values\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'min_radius': self.min_radius,\n",
    "            'max_radius': self.max_radius,\n",
    "            'min_dist': self.min_dist,\n",
    "            'param1': self.param1,\n",
    "            'param2': self.param2\n",
    "        }\n",
    "        \n",
    "    def process_image(self, gray: np.ndarray, hsv: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Complete processing pipeline for M&M detection and classification.\n",
    "        \n",
    "        Args:\n",
    "            gray: Grayscale image\n",
    "            hsv: HSV format image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing detected circles and their colors\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Detect circles\n",
    "            circles = self.detect_circles(gray)\n",
    "            \n",
    "            # Identify colors if circles were found\n",
    "            colors = self.identify_colors(hsv, circles) if len(circles) > 0 else []\n",
    "            \n",
    "            return circles, colors\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in image processing: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def draw_results(self, image: np.ndarray, circles: np.ndarray, \n",
    "                    colors: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draw detection results on the image.\n",
    "        \n",
    "        Args:\n",
    "            image: Original image\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            \n",
    "        Returns:\n",
    "            Image with detection results drawn\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result_image = image.copy()\n",
    "            \n",
    "            for (x, y, r), color in zip(circles, colors):\n",
    "                # Draw circle outline\n",
    "                cv2.circle(result_image, (x, y), r, (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw center point\n",
    "                cv2.circle(result_image, (x, y), 2, (0, 0, 255), 3)\n",
    "                \n",
    "                # Add color label\n",
    "                cv2.putText(result_image, color, (x-20, y-20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                \n",
    "            return result_image\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error drawing results: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes and validates M&M detection results, generating statistics and reports.\n",
    "    \n",
    "    Attributes:\n",
    "        logger: Logging instance for error tracking\n",
    "        history: List of previous results for trend analysis\n",
    "        validation_thresholds: Dictionary of validation thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize result history\n",
    "        self.history: List[Dict] = []\n",
    "        \n",
    "        # Define validation thresholds\n",
    "        self.validation_thresholds = {\n",
    "            'min_count': 1,\n",
    "            'max_count': 50,\n",
    "            'min_radius': 8,\n",
    "            'max_radius': 35,\n",
    "            'min_distance': 15,\n",
    "            'max_overlap': 0.3\n",
    "        }\n",
    "        \n",
    "    def analyze_results(self, circles: np.ndarray, \n",
    "                       colors: List[str],\n",
    "                       timestamp: Optional[datetime.datetime] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze detection results and generate statistics.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            timestamp: Time of detection\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate inputs\n",
    "            if len(circles) != len(colors):\n",
    "                raise ValueError(\"Mismatch between circles and colors count\")\n",
    "                \n",
    "            # Create result dictionary\n",
    "            results = {\n",
    "                'timestamp': timestamp or datetime.datetime.now().isoformat(),\n",
    "                'total_count': len(circles),\n",
    "                'color_distribution': dict(Counter(colors)),\n",
    "                'spatial_statistics': self._calculate_spatial_statistics(circles),\n",
    "                'radius_statistics': self._calculate_radius_statistics(circles),\n",
    "                'validation_results': self._validate_results(circles, colors),\n",
    "                'confidence_metrics': self._calculate_confidence_metrics(circles, colors)\n",
    "            }\n",
    "            \n",
    "            # Add to history\n",
    "            self.history.append(results)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in result analysis: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_spatial_statistics(self, circles: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate spatial statistics for detected M&Ms.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing spatial statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(circles) == 0:\n",
    "                return {'density': 0, 'average_spacing': 0}\n",
    "                \n",
    "            # Extract center points\n",
    "            centers = circles[:, :2]\n",
    "            \n",
    "            # Calculate pairwise distances\n",
    "            distances = []\n",
    "            for i in range(len(centers)):\n",
    "                for j in range(i + 1, len(centers)):\n",
    "                    dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                    distances.append(dist)\n",
    "                    \n",
    "            # Calculate area\n",
    "            area = (np.max(centers[:, 0]) - np.min(centers[:, 0])) * \\\n",
    "                   (np.max(centers[:, 1]) - np.min(centers[:, 1]))\n",
    "                   \n",
    "            stats = {\n",
    "                'density': len(circles) / area if area > 0 else 0,\n",
    "                'average_spacing': np.mean(distances) if distances else 0,\n",
    "                'min_spacing': np.min(distances) if distances else 0,\n",
    "                'max_spacing': np.max(distances) if distances else 0,\n",
    "                'spacing_std': np.std(distances) if distances else 0\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating spatial statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_radius_statistics(self, circles: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate statistics for M&M radii.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing radius statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(circles) == 0:\n",
    "                return {\n",
    "                    'average_radius': 0,\n",
    "                    'radius_std': 0,\n",
    "                    'min_radius': 0,\n",
    "                    'max_radius': 0\n",
    "                }\n",
    "                \n",
    "            radii = circles[:, 2]\n",
    "            \n",
    "            stats = {\n",
    "                'average_radius': float(np.mean(radii)),\n",
    "                'radius_std': float(np.std(radii)),\n",
    "                'min_radius': float(np.min(radii)),\n",
    "                'max_radius': float(np.max(radii)),\n",
    "                'radius_variation': float(np.std(radii) / np.mean(radii))\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating radius statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_confidence_metrics(self, circles: np.ndarray, \n",
    "                                   colors: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate confidence metrics for detection results.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing confidence metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            metrics = {\n",
    "                'detection_confidence': 0.0,\n",
    "                'color_confidence': 0.0,\n",
    "                'overall_confidence': 0.0\n",
    "            }\n",
    "            \n",
    "            if len(circles) == 0:\n",
    "                return metrics\n",
    "                \n",
    "            # Detection confidence based on radius consistency\n",
    "            radii = circles[:, 2]\n",
    "            radius_variation = np.std(radii) / np.mean(radii)\n",
    "            detection_confidence = max(0, 1 - radius_variation)\n",
    "            \n",
    "            # Color confidence based on known colors\n",
    "            known_colors = len([c for c in colors if c != 'unknown'])\n",
    "            color_confidence = known_colors / len(colors) if colors else 0\n",
    "            \n",
    "            # Overall confidence\n",
    "            metrics.update({\n",
    "                'detection_confidence': float(detection_confidence),\n",
    "                'color_confidence': float(color_confidence),\n",
    "                'overall_confidence': float((detection_confidence + color_confidence) / 2)\n",
    "            })\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating confidence metrics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _validate_results(self, circles: np.ndarray, colors: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Validate detection results against thresholds.\n",
    "        \n",
    "        Args:\n",
    "            circles: Detected circles\n",
    "            colors: Identified colors\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing validation results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            validation = {\n",
    "                'count_valid': True,\n",
    "                'radius_valid': True,\n",
    "                'spacing_valid': True,\n",
    "                'overlap_valid': True,\n",
    "                'warnings': []\n",
    "            }\n",
    "            \n",
    "            # Validate count\n",
    "            if len(circles) < self.validation_thresholds['min_count']:\n",
    "                validation['count_valid'] = False\n",
    "                validation['warnings'].append(\"Too few M&Ms detected\")\n",
    "            elif len(circles) > self.validation_thresholds['max_count']:\n",
    "                validation['count_valid'] = False\n",
    "                validation['warnings'].append(\"Too many M&Ms detected\")\n",
    "                \n",
    "            # Validate radii\n",
    "            radii = circles[:, 2]\n",
    "            if np.any(radii < self.validation_thresholds['min_radius']) or \\\n",
    "               np.any(radii > self.validation_thresholds['max_radius']):\n",
    "                validation['radius_valid'] = False\n",
    "                validation['warnings'].append(\"Invalid M&M sizes detected\")\n",
    "                \n",
    "            # Validate spacing\n",
    "            centers = circles[:, :2]\n",
    "            for i in range(len(centers)):\n",
    "                for j in range(i + 1, len(centers)):\n",
    "                    dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                    if dist < self.validation_thresholds['min_distance']:\n",
    "                        validation['spacing_valid'] = False\n",
    "                        validation['warnings'].append(\"M&Ms too close together\")\n",
    "                        break\n",
    "                        \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in result validation: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def generate_report(self, results: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Generate a formatted report of analysis results.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            report = [\n",
    "                \"M&M Detection Analysis Report\",\n",
    "                f\"Timestamp: {results['timestamp']}\",\n",
    "                f\"\\nTotal M&Ms detected: {results['total_count']}\",\n",
    "                \"\\nColor Distribution:\"\n",
    "            ]\n",
    "            \n",
    "            for color, count in results['color_distribution'].items():\n",
    "                report.append(f\"  {color}: {count}\")\n",
    "                \n",
    "            report.extend([\n",
    "                \"\\nSpatial Statistics:\",\n",
    "                f\"  Average spacing: {results['spatial_statistics']['average_spacing']:.2f} pixels\",\n",
    "                f\"  Density: {results['spatial_statistics']['density']:.4f} M&Ms/pixelÂ²\",\n",
    "                \"\\nSize Statistics:\",\n",
    "                f\"  Average radius: {results['radius_statistics']['average_radius']:.2f} pixels\",\n",
    "                f\"  Radius std dev: {results['radius_statistics']['radius_std']:.2f} pixels\",\n",
    "                \"\\nConfidence Metrics:\",\n",
    "                f\"  Detection confidence: {results['confidence_metrics']['detection_confidence']:.2%}\",\n",
    "                f\"  Color confidence: {results['confidence_metrics']['color_confidence']:.2%}\",\n",
    "                f\"  Overall confidence: {results['confidence_metrics']['overall_confidence']:.2%}\"\n",
    "            ])\n",
    "            \n",
    "            if results['validation_results']['warnings']:\n",
    "                report.extend([\n",
    "                    \"\\nWarnings:\",\n",
    "                    *[f\"  - {warning}\" for warning in results['validation_results']['warnings']]\n",
    "                ])\n",
    "                \n",
    "            return \"\\n\".join(report)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating report: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def plot_results(self, results: Dict, save_path: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Generate visualization plots for results.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            save_path: Optional path to save plots\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.style.use('seaborn')\n",
    "            \n",
    "            # Create figure with subplots\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Color distribution\n",
    "            ax1 = plt.subplot(2, 2, 1)\n",
    "            colors = list(results['color_distribution'].keys())\n",
    "            counts = list(results['color_distribution'].values())\n",
    "            ax1.bar(colors, counts)\n",
    "            ax1.set_title('Color Distribution')\n",
    "            ax1.set_xlabel('Color')\n",
    "            ax1.set_ylabel('Count')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Radius distribution\n",
    "            ax2 = plt.subplot(2, 2, 2)\n",
    "            ax2.hist(results['radius_statistics']['average_radius'], bins=10)\n",
    "            ax2.set_title('Radius Distribution')\n",
    "            ax2.set_xlabel('Radius (pixels)')\n",
    "            ax2.set_ylabel('Frequency')\n",
    "            \n",
    "            # Confidence metrics\n",
    "            ax3 = plt.subplot(2, 2, 3)\n",
    "            confidence_metrics = results['confidence_metrics']\n",
    "            ax3.bar(['Detection', 'Color', 'Overall'], \n",
    "                   [confidence_metrics['detection_confidence'],\n",
    "                    confidence_metrics['color_confidence'],\n",
    "                    confidence_metrics['overall_confidence']])\n",
    "            ax3.set_title('Confidence Metrics')\n",
    "            ax3.set_ylim(0, 1)\n",
    "            \n",
    "            # Spatial distribution\n",
    "            ax4 = plt.subplot(2, 2, 4)\n",
    "            spatial_stats = results['spatial_statistics']\n",
    "            ax4.bar(['Min', 'Avg', 'Max'],\n",
    "                   [spatial_stats['min_spacing'],\n",
    "                    spatial_stats['average_spacing'],\n",
    "                    spatial_stats['max_spacing']])\n",
    "            ax4.set_title('Spacing Distribution')\n",
    "            ax4.set_ylabel('Pixels')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error plotting results: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def save_results(self, results: Dict, filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save results to JSON file.\n",
    "        \n",
    "        Args:\n",
    "            results: Analysis results dictionary\n",
    "            filepath: Path to save file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "                \n",
    "            self.logger.info(f\"Results saved to {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving results: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def get_history_statistics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate statistics across historical results.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing historical statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.history:\n",
    "                return {}\n",
    "                \n",
    "            total_counts = [result['total_count'] for result in self.history]\n",
    "            \n",
    "            stats = {\n",
    "                'average_count': np.mean(total_counts),\n",
    "                'count_std': np.std(total_counts),\n",
    "                'min_count': min(total_counts),\n",
    "                'max_count': max(total_counts),\n",
    "                'total_analyses': len(self.history),\n",
    "                'color_frequencies': self._calculate_color_frequencies()\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating history statistics: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _calculate_color_frequencies(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate color frequencies across all historical results.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing color frequencies\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.history:\n",
    "                return {}\n",
    "                \n",
    "            all_colors = []\n",
    "            for result in self.history:\n",
    "                all_colors.extend(result['color_distribution'].keys())\n",
    "                \n",
    "            return dict(Counter(all_colors))\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating color frequencies: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCounterGUI:\n",
    "    \"\"\"\n",
    "    Main GUI application for M&M Counter System.\n",
    "    \n",
    "    Integrates all components:\n",
    "    - WebcamCapture for image acquisition\n",
    "    - ImageProcessor for image processing\n",
    "    - MMDetector for M&M detection\n",
    "    - ResultAnalyzer for result analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the GUI application and all components.\"\"\"\n",
    "        self.setup_logging()\n",
    "        self.setup_components()\n",
    "        self.setup_gui()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging system.\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def setup_components(self):\n",
    "        \"\"\"Initialize all system components.\"\"\"\n",
    "        try:\n",
    "            self.webcam = WebcamCapture()\n",
    "            self.processor = ImageProcessor()\n",
    "            self.detector = MMDetector()\n",
    "            self.analyzer = ResultAnalyzer()\n",
    "            \n",
    "            # Initialize state variables\n",
    "            self.current_image = None\n",
    "            self.current_results = None\n",
    "            self.is_processing = False\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing components: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Set up the graphical user interface.\"\"\"\n",
    "        try:\n",
    "            self.root = tk.Tk()\n",
    "            self.root.title(\"M&M Counter System\")\n",
    "            self.root.geometry(\"1200x800\")\n",
    "            \n",
    "            # Create main container with padding\n",
    "            self.main_container = ttk.Frame(self.root, padding=\"10\")\n",
    "            self.main_container.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            \n",
    "            # Configure grid weights\n",
    "            self.root.columnconfigure(0, weight=1)\n",
    "            self.root.rowconfigure(0, weight=1)\n",
    "            self.main_container.columnconfigure(1, weight=1)\n",
    "            self.main_container.rowconfigure(1, weight=1)\n",
    "            \n",
    "            self.setup_control_panel()\n",
    "            self.setup_image_display()\n",
    "            self.setup_results_panel()\n",
    "            self.setup_status_bar()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up GUI: {str(e)}\")\n",
    "            raise\n",
    "    def setup_control_panel(self):\n",
    "        \"\"\"Set up the control panel with buttons and options.\"\"\"\n",
    "        try:\n",
    "            # Create main control frame\n",
    "            control_frame = ttk.LabelFrame(self.main_container, text=\"Controls\", padding=\"5\")\n",
    "            control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N), padx=5, pady=5)\n",
    "            \n",
    "            # File operations\n",
    "            file_frame = ttk.LabelFrame(control_frame, text=\"File Operations\", padding=\"5\")\n",
    "            file_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(file_frame, text=\"Load Image\", \n",
    "                      command=self.load_image).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(file_frame, text=\"Save Results\", \n",
    "                      command=self.save_results).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            # Camera operations\n",
    "            camera_frame = ttk.LabelFrame(control_frame, text=\"Camera Control\", padding=\"5\")\n",
    "            camera_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(camera_frame, text=\"Start Camera\", \n",
    "                      command=self.start_camera).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(camera_frame, text=\"Capture\", \n",
    "                      command=self.capture_from_webcam).grid(row=0, column=1, padx=2)\n",
    "            ttk.Button(camera_frame, text=\"Stop Camera\", \n",
    "                      command=self.stop_camera).grid(row=0, column=2, padx=2)\n",
    "            \n",
    "            # Processing controls\n",
    "            process_frame = ttk.LabelFrame(control_frame, text=\"Processing\", padding=\"5\")\n",
    "            process_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            ttk.Button(process_frame, text=\"Process Image\", \n",
    "                      command=self.process_image).grid(row=0, column=0, padx=2)\n",
    "            ttk.Button(process_frame, text=\"Clear\", \n",
    "                      command=self.clear_display).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            # Settings\n",
    "            settings_frame = ttk.LabelFrame(control_frame, text=\"Settings\", padding=\"5\")\n",
    "            settings_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            # Detection parameters\n",
    "            ttk.Label(settings_frame, text=\"Min Radius:\").grid(row=0, column=0, padx=2)\n",
    "            self.min_radius_var = tk.StringVar(value=str(self.detector.min_radius))\n",
    "            ttk.Entry(settings_frame, textvariable=self.min_radius_var, \n",
    "                     width=5).grid(row=0, column=1, padx=2)\n",
    "            \n",
    "            ttk.Label(settings_frame, text=\"Max Radius:\").grid(row=0, column=2, padx=2)\n",
    "            self.max_radius_var = tk.StringVar(value=str(self.detector.max_radius))\n",
    "            ttk.Entry(settings_frame, textvariable=self.max_radius_var, \n",
    "                     width=5).grid(row=0, column=3, padx=2)\n",
    "            \n",
    "            ttk.Button(settings_frame, text=\"Apply\", \n",
    "                      command=self.apply_settings).grid(row=0, column=4, padx=5)\n",
    "            \n",
    "            # Analysis options\n",
    "            analysis_frame = ttk.LabelFrame(control_frame, text=\"Analysis Options\", padding=\"5\")\n",
    "            analysis_frame.grid(row=4, column=0, sticky=(tk.W, tk.E), pady=5)\n",
    "            \n",
    "            self.show_colors_var = tk.BooleanVar(value=True)\n",
    "            ttk.Checkbutton(analysis_frame, text=\"Show Colors\", \n",
    "                           variable=self.show_colors_var).grid(row=0, column=0)\n",
    "            \n",
    "            self.show_centers_var = tk.BooleanVar(value=True)\n",
    "            ttk.Checkbutton(analysis_frame, text=\"Show Centers\", \n",
    "                           variable=self.show_centers_var).grid(row=0, column=1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up control panel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_image_display(self):\n",
    "        \"\"\"Set up the image display area.\"\"\"\n",
    "        try:\n",
    "            display_frame = ttk.LabelFrame(self.main_container, text=\"Image Display\", padding=\"5\")\n",
    "            display_frame.grid(row=0, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)\n",
    "            \n",
    "            self.image_label = ttk.Label(display_frame)\n",
    "            self.image_label.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            \n",
    "            # Configure grid weights\n",
    "            display_frame.columnconfigure(0, weight=1)\n",
    "            display_frame.rowconfigure(0, weight=1)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up image display: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_results_panel(self):\n",
    "        \"\"\"Set up the results display panel.\"\"\"\n",
    "        try:\n",
    "            results_frame = ttk.LabelFrame(self.main_container, text=\"Results\", padding=\"5\")\n",
    "            results_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)\n",
    "            \n",
    "            # Results text display with scrollbar\n",
    "            self.results_text = tk.Text(results_frame, height=10, width=40)\n",
    "            scrollbar = ttk.Scrollbar(results_frame, orient=tk.VERTICAL, \n",
    "                                    command=self.results_text.yview)\n",
    "            \n",
    "            self.results_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "            scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))\n",
    "            \n",
    "            self.results_text['yscrollcommand'] = scrollbar.set\n",
    "            \n",
    "            # Configure grid weights\n",
    "            results_frame.columnconfigure(0, weight=1)\n",
    "            results_frame.rowconfigure(0, weight=1)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up results panel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def setup_status_bar(self):\n",
    "        \"\"\"Set up the status bar.\"\"\"\n",
    "        try:\n",
    "            self.status_var = tk.StringVar()\n",
    "            self.status_var.set(\"Ready\")\n",
    "            \n",
    "            status_bar = ttk.Label(self.main_container, textvariable=self.status_var, \n",
    "                                 relief=tk.SUNKEN)\n",
    "            status_bar.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up status bar: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def apply_settings(self):\n",
    "        \"\"\"Apply detection parameter settings.\"\"\"\n",
    "        try:\n",
    "            # Update detector parameters\n",
    "            min_radius = int(self.min_radius_var.get())\n",
    "            max_radius = int(self.max_radius_var.get())\n",
    "            \n",
    "            self.detector.adjust_detection_params(\n",
    "                min_radius=min_radius,\n",
    "                max_radius=max_radius\n",
    "            )\n",
    "            \n",
    "            self.status_var.set(\"Detection parameters updated\")\n",
    "            \n",
    "            # Reprocess current image if available\n",
    "            if self.current_image is not None:\n",
    "                self.process_image()\n",
    "                \n",
    "        except ValueError as e:\n",
    "            messagebox.showerror(\"Error\", \"Invalid parameter values\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error applying settings: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to apply settings: {str(e)}\")\n",
    "\n",
    "    def load_image(self):\n",
    "        \"\"\"Load image from file.\"\"\"\n",
    "        try:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=\"Select Image\",\n",
    "                filetypes=[\n",
    "                    (\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.gif *.tiff\"),\n",
    "                    (\"All files\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                self.current_image = cv2.imread(file_path)\n",
    "                if self.current_image is None:\n",
    "                    raise ValueError(\"Failed to load image\")\n",
    "                    \n",
    "                self.display_image(self.current_image)\n",
    "                self.status_var.set(f\"Loaded image: {os.path.basename(file_path)}\")\n",
    "                self.logger.info(f\"Loaded image from {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading image: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load image: {str(e)}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save current results to file.\"\"\"\n",
    "        try:\n",
    "            if self.current_results is None:\n",
    "                messagebox.showwarning(\"Warning\", \"No results to save\")\n",
    "                return\n",
    "                \n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=\".json\",\n",
    "                filetypes=[(\"JSON files\", \"*.json\")]\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                self.analyzer.save_results(self.current_results, file_path)\n",
    "                self.status_var.set(f\"Results saved to {os.path.basename(file_path)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving results: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to save results: {str(e)}\")\n",
    "\n",
    "    def start_camera(self):\n",
    "        \"\"\"Initialize and start the webcam preview.\"\"\"\n",
    "        try:\n",
    "            if self.webcam.initialize_camera():\n",
    "                self.preview_window = tk.Toplevel(self.root)\n",
    "                self.preview_window.title(\"Camera Preview\")\n",
    "                self.preview_label = ttk.Label(self.preview_window)\n",
    "                self.preview_label.pack()\n",
    "                \n",
    "                self.update_preview()\n",
    "                self.status_var.set(\"Camera preview active\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Failed to initialize camera\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error starting camera: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to start camera: {str(e)}\")\n",
    "\n",
    "    def update_preview(self):\n",
    "        \"\"\"Update the camera preview.\"\"\"\n",
    "        if hasattr(self, 'preview_window'):\n",
    "            frame = self.webcam.capture_frame()\n",
    "            if frame is not None:\n",
    "                self.display_image(frame, preview=True)\n",
    "                self.root.after(10, self.update_preview)\n",
    "\n",
    "    def capture_from_webcam(self):\n",
    "        \"\"\"Capture image from webcam.\"\"\"\n",
    "        try:\n",
    "            frame = self.webcam.capture_frame()\n",
    "            if frame is not None:\n",
    "                self.current_image = frame\n",
    "                self.display_image(frame)\n",
    "                self.status_var.set(\"Image captured from webcam\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Failed to capture image\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error capturing from webcam: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to capture image: {str(e)}\")\n",
    "\n",
    "    def stop_camera(self):\n",
    "        \"\"\"Stop the webcam preview and release resources.\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'preview_window'):\n",
    "                self.preview_window.destroy()\n",
    "                delattr(self, 'preview_window')\n",
    "                \n",
    "            self.webcam.release()\n",
    "            self.status_var.set(\"Camera stopped\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error stopping camera: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to stop camera: {str(e)}\")\n",
    "\n",
    "    def process_image(self):\n",
    "        \"\"\"Process the current image and detect M&Ms.\"\"\"\n",
    "        try:\n",
    "            if self.current_image is None:\n",
    "                messagebox.showwarning(\"Warning\", \"No image loaded\")\n",
    "                return\n",
    "                \n",
    "            if self.is_processing:\n",
    "                return\n",
    "                \n",
    "            self.is_processing = True\n",
    "            self.status_var.set(\"Processing image...\")\n",
    "            \n",
    "            # Process image\n",
    "            gray, hsv, blurred = self.processor.process_for_detection(self.current_image)\n",
    "            \n",
    "            # Detect M&Ms\n",
    "            circles, colors = self.detector.process_image(gray, hsv)\n",
    "            \n",
    "            if len(circles) == 0:\n",
    "                self.status_var.set(\"No M&Ms detected\")\n",
    "                return\n",
    "                \n",
    "            # Analyze results\n",
    "            self.current_results = self.analyzer.analyze_results(circles, colors)\n",
    "            \n",
    "            # Display results\n",
    "            self.display_results(self.current_results)\n",
    "            \n",
    "            # Display processed image\n",
    "            result_image = self.detector.draw_results(self.current_image, circles, colors)\n",
    "            self.display_image(result_image)\n",
    "            \n",
    "            self.status_var.set(f\"Detected {len(circles)} M&Ms\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing image: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to process image: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            self.is_processing = False\n",
    "\n",
    "    def display_image(self, image: np.ndarray, preview: bool = False):\n",
    "        \"\"\"Display image in GUI.\"\"\"\n",
    "        try:\n",
    "            # Convert BGR to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            pil_image = Image.fromarray(image_rgb)\n",
    "            \n",
    "            # Resize if needed\n",
    "            display_size = (800, 600)\n",
    "            pil_image.thumbnail(display_size, Image.LANCZOS)\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            photo = ImageTk.PhotoImage(pil_image)\n",
    "            \n",
    "            # Update display\n",
    "            if preview:\n",
    "                self.preview_label.configure(image=photo)\n",
    "                self.preview_label.image = photo\n",
    "            else:\n",
    "                self.image_label.configure(image=photo)\n",
    "                self.image_label.image = photo\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error displaying image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def display_results(self, results: Dict):\n",
    "        \"\"\"Display analysis results in GUI.\"\"\"\n",
    "        try:\n",
    "            report = self.analyzer.generate_report(results)\n",
    "            self.results_text.delete(1.0, tk.END)\n",
    "            self.results_text.insert(tk.END, report)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error displaying results: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to display results: {str(e)}\")\n",
    "\n",
    "    def clear_display(self):\n",
    "        \"\"\"Clear the current image and results.\"\"\"\n",
    "        self.current_image = None\n",
    "        self.current_results = None\n",
    "        self.image_label.configure(image='')\n",
    "        self.results_text.delete(1.0, tk.END)\n",
    "        self.status_var.set(\"Display cleared\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Start the GUI application.\"\"\"\n",
    "        try:\n",
    "            self.root.mainloop()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Application error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Cleanup resources on deletion.\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'webcam'):\n",
    "                self.webcam.release()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the application\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        app = MMCounterGUI()\n",
    "        app.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting application: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Notes on Sample Code\n",
    "\n",
    "There are two ways to run this Jupyter Notebook document:\n",
    "- Via [Google Colab](https://colab.research.google.com/), or\n",
    "- On your own desktop PC.\n",
    "\n",
    "To further develop this code on your desktop, you can:\n",
    "- Install a [Python](https://www.python.org/) environment using [Anaconda](https://www.anaconda.com/download).\n",
    "  - Installation instructions can be found [here](https://docs.anaconda.com/anaconda/install/).\n",
    "  - To run the sample code above, after installing the base Python environment, make sure that [OpenCV](https://opencv.org/) is also installed via Anaconda.\n",
    "  - If you decide to incorporate machine learning, additional dependencies can be installed either via [Anaconda](https://www.anaconda.com/download) or [pip](https://pypi.org/project/pip/).\n",
    "- Install Microsoft [Visual Studio Code](https://code.visualstudio.com/) as a Jupyter Notebook environment.\n",
    "  - An introduction to using Jupyter Notebooks in VS Code can be found [here](https://code.visualstudio.com/docs/datascience/jupyter-notebooks).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
